{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from maze_dataset.plotting import MazePlot\n",
    "import random\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/atul/diffusion-based-environment-generator/generator\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/home/atul/diffusion-based-environment-generator/generator\")\n",
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/grid/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grid Worlds: 100%|██████████| 10000/10000 [00:02<00:00, 4699.33it/s]\n",
      "Processing Mazes: 100%|██████████| 10000/10000 [00:03<00:00, 2707.52maze/s]\n"
     ]
    }
   ],
   "source": [
    "from maze.grid_world_generator import generate_multiple_grid_worlds\n",
    "from maze.solvers.a_star_l2 import main\n",
    "\n",
    "generate_multiple_grid_worlds(10_000, 10)\n",
    "main() # main function of a_star\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorldDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        # print(directory)\n",
    "        self.files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.npy')]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # print(self.files[idx])\n",
    "        grid = np.load(self.files[idx])\n",
    "        return torch.tensor(grid, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grid_world(grid):\n",
    "    \"\"\"\n",
    "    Plots the given grid world.\n",
    "    \"\"\"\n",
    "    wall = grid[:,:,0] == 0\n",
    "    source = grid[:,:,1] == 1\n",
    "    destination = grid[:,:,2] == 1\n",
    "\n",
    "    # Below is ChatGPT   \n",
    "    img = np.ones((*wall.shape, 3), dtype=np.float32)  # White background\n",
    "    img[wall] = np.array([0, 0, 0])  # Walls → Black\n",
    "    img[source] = np.array([0, 0, 1])  # Source → Blue\n",
    "    img[destination] = np.array([0, 1, 0])  # Destination → Green\n",
    "    \n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = GridWorldDataset(\"/home/atul/diffusion-based-environment-generator/generator/data/grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_grid_text(grid):\n",
    "    \"\"\"\n",
    "    Displays the grid world in text format.\n",
    "    \"\"\"\n",
    "    height, width = grid.shape[1], grid.shape[2]\n",
    "    char_grid = np.full((height, width), '-', dtype=str)\n",
    "    \n",
    "    wall = grid[:, :, 0] == 0\n",
    "    source = grid[:, :, 1] == 1\n",
    "    destination = grid[:, :, 2] == 1\n",
    "    \n",
    "    char_grid = np.full(wall.shape, '-', dtype=str)  # Default to empty space\n",
    "    char_grid[wall] = '#'  # Walls\n",
    "    char_grid[source] = 'S'  # Source\n",
    "    char_grid[destination] = 'E'  # Destination\n",
    "    \n",
    "    print(\"\\n\".join(\"\".join(row) for row in char_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_grid_world(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----#---#\n",
      "####--#---\n",
      "---#---##-\n",
      "---#---#-#\n",
      "##-#---#-#\n",
      "--#----E-#\n",
      "---##-----\n",
      "#--#-##---\n",
      "#----#----\n",
      "#S-#------\n"
     ]
    }
   ],
   "source": [
    "display_grid_text(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from maze_dataset.plotting import MazePlot\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/atul/diffusion-based-environment-generator/generator\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify sigmoid layer for sharper output\n",
    "class SharpSigmoid(nn.Module):\n",
    "    def __init__(self, sharpness_factor=5.0):\n",
    "        super(SharpSigmoid, self).__init__()\n",
    "        self.sharpness_factor = sharpness_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.sharpness_factor * x)\n",
    "\n",
    "\n",
    "class RandomSignFlip(nn.Module):\n",
    "    def __init__(self, flip_prob=0.01):\n",
    "        super(RandomSignFlip, self).__init__()\n",
    "        self.flip_prob = flip_prob\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Generate a mask with 20% probability of flipping the sign\n",
    "        flip_mask = torch.rand(x.shape, device=x.device) < self.flip_prob  # 20% chance to flip\n",
    "        sign_flip = torch.where(flip_mask, torch.tensor(-1.0, device=x.device), torch.tensor(1.0, device=x.device))\n",
    "        return x * sign_flip  # Apply random sign flip based on the mask\n",
    "\n",
    "class Scale(nn.Module):\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.factor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MazeVAE(nn.Module):\n",
    "    def __init__(self, latent_dim=64):\n",
    "        super(MazeVAE, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(300, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128, latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(256, 300),\n",
    "            # RandomSignFlip(),\n",
    "            nn.Tanh(),\n",
    "            Scale(4),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten: (B, 300)\n",
    "        x = self.encoder(x)\n",
    "        return self.fc_mu(x), self.fc_logvar(x)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        out = self.decoder(z)\n",
    "        return out.view(-1, 10, 10, 3)  # reshape to (B, 10, 10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        recon = self.decode(z)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "    def predict_discrete_structure(self, recon_batch):\n",
    "        \"\"\"\n",
    "        Converts real-valued (B, 10, 10, 3) output into integer maze tensor.\n",
    "        - Channel 0: binary walls\n",
    "        - Channel 1: one-hot source\n",
    "        - Channel 2: one-hot destination\n",
    "        \"\"\"\n",
    "        B = recon_batch.shape[0]\n",
    "\n",
    "        print(recon_batch[..., 0])\n",
    "\n",
    "        wall = (recon_batch[..., 0] >= 0.5).int()\n",
    "\n",
    "        print(\"WALL\")\n",
    "        print(wall)\n",
    "\n",
    "        source_flat = recon_batch[..., 1].view(B, -1)\n",
    "        source_indices = source_flat.argmax(dim=1)\n",
    "        source_onehot = torch.zeros_like(source_flat, dtype=torch.int)\n",
    "        source_onehot[torch.arange(B), source_indices] = 1\n",
    "        source_onehot = source_onehot.view(B, 10, 10)\n",
    "\n",
    "        dest_flat = recon_batch[..., 2].view(B, -1)\n",
    "        dest_indices = dest_flat.argmax(dim=1)\n",
    "        dest_onehot = torch.zeros_like(dest_flat, dtype=torch.int)\n",
    "        dest_onehot[torch.arange(B), dest_indices] = 1\n",
    "        dest_onehot = dest_onehot.view(B, 10, 10)\n",
    "\n",
    "        result = torch.stack([wall, source_onehot, dest_onehot], dim=-1).int()\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "LATENT_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "print(f'Training dataset size: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "vae = MazeVAE(latent_dim=LATENT_DIM)\n",
    "optimizer = optim.Adam(list(vae.parameters()), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectivity_loss(recon_x, max_dist=100.0):\n",
    "    \"\"\"\n",
    "    recon_x: [B, H, W, 3] – output from decoder after sigmoid\n",
    "    \"\"\"\n",
    "    wall_prob = recon_x[..., 0]         # [B, H, W]\n",
    "    source_prob = recon_x[..., 1]       # [B, H, W]\n",
    "    dest_prob = recon_x[..., 2]         # [B, H, W]\n",
    "    \n",
    "    traversable = 1.0 - wall_prob       # higher means more walkable\n",
    "    B, H, W = traversable.shape\n",
    "\n",
    "    # Soft-argmax to get source & destination coordinates\n",
    "    grid_y, grid_x = torch.meshgrid(\n",
    "        torch.linspace(0, 1, H, device=recon_x.device),\n",
    "        torch.linspace(0, 1, W, device=recon_x.device),\n",
    "        indexing='ij'\n",
    "    )  # both [H, W]\n",
    "\n",
    "    grid_x = grid_x.unsqueeze(0)  # [1, H, W]\n",
    "    grid_y = grid_y.unsqueeze(0)\n",
    "\n",
    "    # Normalize source/dest masks\n",
    "    source_prob = source_prob / (source_prob.sum(dim=(1,2), keepdim=True) + 1e-8)\n",
    "    dest_prob = dest_prob / (dest_prob.sum(dim=(1,2), keepdim=True) + 1e-8)\n",
    "\n",
    "    # Compute soft coordinates\n",
    "    src_x = (grid_x * source_prob).sum(dim=(1,2))\n",
    "    src_y = (grid_y * source_prob).sum(dim=(1,2))\n",
    "    dst_x = (grid_x * dest_prob).sum(dim=(1,2))\n",
    "    dst_y = (grid_y * dest_prob).sum(dim=(1,2))\n",
    "\n",
    "    # Compute squared distance (proxy for disconnected if very large)\n",
    "    dist_sq = (src_x - dst_x)**2 + (src_y - dst_y)**2  # [B]\n",
    "\n",
    "    # Invert: higher dist → higher loss\n",
    "    loss = dist_sq / (max_dist ** 2)\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_q_error(x, recon_x):\n",
    "    # Extract one-hot source/destination\n",
    "    src_true = (x[..., 1] == x[..., 1].amax(dim=(1, 2), keepdim=True)).float()\n",
    "    dst_true = (x[..., 2] == x[..., 2].amax(dim=(1, 2), keepdim=True)).float()\n",
    "    \n",
    "    src_pred = (recon_x[..., 1] == recon_x[..., 1].amax(dim=(1, 2), keepdim=True)).float()\n",
    "    dst_pred = (recon_x[..., 2] == recon_x[..., 2].amax(dim=(1, 2), keepdim=True)).float()\n",
    "    \n",
    "    # Get (x, y) positions: shape [B, 2]\n",
    "    def get_coords(mask):\n",
    "        B = mask.shape[0]\n",
    "        H, W = mask.shape[1:3]\n",
    "        flat = mask.view(B, -1)  # [B, H*W]\n",
    "        idx = flat.argmax(dim=1)  # [B]\n",
    "        x = idx // W\n",
    "        y = idx % W\n",
    "        return torch.stack((x, y), dim=1)  # [B, 2]\n",
    "\n",
    "    src_true_xy = get_coords(src_true)\n",
    "    dst_true_xy = get_coords(dst_true)\n",
    "    src_pred_xy = get_coords(src_pred)\n",
    "    dst_pred_xy = get_coords(dst_pred)\n",
    "\n",
    "    # Manhattan distances\n",
    "    dist_true = (src_true_xy - dst_true_xy).abs().sum(dim=1)  # [B]\n",
    "    dist_pred = (src_pred_xy - dst_pred_xy).abs().sum(dim=1)  # [B]\n",
    "\n",
    "    # Avoid division by zero by adding 1\n",
    "    min_dist = torch.min(dist_true, dist_pred).clamp(min=1.0)\n",
    "    max_dist = torch.max(dist_true, dist_pred)\n",
    "\n",
    "    q_error = max_dist / min_dist  # [B]\n",
    "    return q_error.sum()  # scalar\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar, zero_weight=2.0, kl_weight=1.0):\n",
    "    weight = torch.ones_like(x)\n",
    "    weight[..., 0] = torch.where(x[..., 0] == 0, zero_weight, 1.0)\n",
    "    \n",
    "    BCE = F.binary_cross_entropy(recon_x, x, weight=weight, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    # Ignore this and set it to 0 for now\n",
    "    q_error = compute_q_error(x, recon_x) * 0\n",
    "\n",
    "    batch_size = recon_x.shape[0]\n",
    "    \n",
    "    return (BCE + kl_weight * KLD + q_error) / batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_vae(model, dataloader, epochs=10, lr=1e-3, device='cuda'):\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        loop = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\")\n",
    "\n",
    "        for batch in loop:\n",
    "            batch = batch.to(torch.float32).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(batch)\n",
    "            loss = loss_function(recon_batch, batch, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            loop.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader.dataset)\n",
    "        print(f\"Epoch {epoch+1} | Avg Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|██████████| 157/157 [00:01<00:00, 103.40it/s, loss=105] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Avg Loss: 1.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|██████████| 157/157 [00:01<00:00, 139.75it/s, loss=104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Avg Loss: 1.5902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|██████████| 157/157 [00:01<00:00, 135.89it/s, loss=104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Avg Loss: 1.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|██████████| 157/157 [00:01<00:00, 139.95it/s, loss=104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Avg Loss: 1.5832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|██████████| 157/157 [00:01<00:00, 111.39it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Avg Loss: 1.5814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|██████████| 157/157 [00:01<00:00, 97.37it/s, loss=103]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Avg Loss: 1.5798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|██████████| 157/157 [00:01<00:00, 85.79it/s, loss=104] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Avg Loss: 1.5790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|██████████| 157/157 [00:01<00:00, 109.59it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Avg Loss: 1.5774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|██████████| 157/157 [00:01<00:00, 107.97it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Avg Loss: 1.5761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|██████████| 157/157 [00:01<00:00, 110.66it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Avg Loss: 1.5750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|██████████| 157/157 [00:01<00:00, 106.56it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Avg Loss: 1.5752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|██████████| 157/157 [00:01<00:00, 115.51it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Avg Loss: 1.5739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|██████████| 157/157 [00:01<00:00, 115.50it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Avg Loss: 1.5733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: 100%|██████████| 157/157 [00:01<00:00, 106.54it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Avg Loss: 1.5725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: 100%|██████████| 157/157 [00:01<00:00, 133.63it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Avg Loss: 1.5724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: 100%|██████████| 157/157 [00:01<00:00, 149.87it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Avg Loss: 1.5706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: 100%|██████████| 157/157 [00:01<00:00, 133.01it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Avg Loss: 1.5708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: 100%|██████████| 157/157 [00:01<00:00, 124.19it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Avg Loss: 1.5697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: 100%|██████████| 157/157 [00:01<00:00, 136.62it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Avg Loss: 1.5690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: 100%|██████████| 157/157 [00:01<00:00, 128.18it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Avg Loss: 1.5689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: 100%|██████████| 157/157 [00:01<00:00, 123.02it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Avg Loss: 1.5679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: 100%|██████████| 157/157 [00:01<00:00, 143.31it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Avg Loss: 1.5675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: 100%|██████████| 157/157 [00:01<00:00, 145.89it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Avg Loss: 1.5671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100: 100%|██████████| 157/157 [00:01<00:00, 125.57it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Avg Loss: 1.5677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100: 100%|██████████| 157/157 [00:01<00:00, 141.97it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Avg Loss: 1.5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100: 100%|██████████| 157/157 [00:01<00:00, 124.63it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Avg Loss: 1.5666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100: 100%|██████████| 157/157 [00:01<00:00, 122.02it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Avg Loss: 1.5663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100: 100%|██████████| 157/157 [00:01<00:00, 144.24it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Avg Loss: 1.5665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100: 100%|██████████| 157/157 [00:01<00:00, 141.74it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Avg Loss: 1.5661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100: 100%|██████████| 157/157 [00:01<00:00, 127.52it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Avg Loss: 1.5658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100: 100%|██████████| 157/157 [00:01<00:00, 142.95it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Avg Loss: 1.5659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100: 100%|██████████| 157/157 [00:01<00:00, 132.81it/s, loss=103] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Avg Loss: 1.5655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100: 100%|██████████| 157/157 [00:01<00:00, 128.58it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Avg Loss: 1.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100: 100%|██████████| 157/157 [00:01<00:00, 145.32it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Avg Loss: 1.5646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100: 100%|██████████| 157/157 [00:01<00:00, 136.41it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Avg Loss: 1.5650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100: 100%|██████████| 157/157 [00:01<00:00, 137.72it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Avg Loss: 1.5646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100: 100%|██████████| 157/157 [00:01<00:00, 149.52it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Avg Loss: 1.5650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100: 100%|██████████| 157/157 [00:01<00:00, 137.37it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Avg Loss: 1.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100: 100%|██████████| 157/157 [00:01<00:00, 139.86it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Avg Loss: 1.5638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100: 100%|██████████| 157/157 [00:01<00:00, 134.86it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Avg Loss: 1.5643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100: 100%|██████████| 157/157 [00:01<00:00, 130.59it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Avg Loss: 1.5634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100: 100%|██████████| 157/157 [00:01<00:00, 144.58it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Avg Loss: 1.5641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100: 100%|██████████| 157/157 [00:01<00:00, 141.08it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Avg Loss: 1.5628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100: 100%|██████████| 157/157 [00:01<00:00, 126.55it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Avg Loss: 1.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100: 100%|██████████| 157/157 [00:01<00:00, 143.06it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Avg Loss: 1.5636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100: 100%|██████████| 157/157 [00:01<00:00, 140.43it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Avg Loss: 1.5629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100: 100%|██████████| 157/157 [00:01<00:00, 132.53it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Avg Loss: 1.5626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100: 100%|██████████| 157/157 [00:01<00:00, 143.76it/s, loss=99.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Avg Loss: 1.5631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100: 100%|██████████| 157/157 [00:01<00:00, 133.22it/s, loss=102] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Avg Loss: 1.5623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100: 100%|██████████| 157/157 [00:01<00:00, 139.09it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Avg Loss: 1.5626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100: 100%|██████████| 157/157 [00:01<00:00, 142.30it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Avg Loss: 1.5620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100: 100%|██████████| 157/157 [00:01<00:00, 140.32it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Avg Loss: 1.5619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100: 100%|██████████| 157/157 [00:01<00:00, 143.85it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Avg Loss: 1.5613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100: 100%|██████████| 157/157 [00:01<00:00, 127.35it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Avg Loss: 1.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100: 100%|██████████| 157/157 [00:01<00:00, 148.05it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Avg Loss: 1.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100: 100%|██████████| 157/157 [00:01<00:00, 135.56it/s, loss=99.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Avg Loss: 1.5612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100: 100%|██████████| 157/157 [00:01<00:00, 128.24it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Avg Loss: 1.5601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100: 100%|██████████| 157/157 [00:01<00:00, 146.37it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Avg Loss: 1.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100: 100%|██████████| 157/157 [00:01<00:00, 131.52it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Avg Loss: 1.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100: 100%|██████████| 157/157 [00:01<00:00, 147.65it/s, loss=99.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Avg Loss: 1.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100: 100%|██████████| 157/157 [00:01<00:00, 148.95it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Avg Loss: 1.5597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100: 100%|██████████| 157/157 [00:01<00:00, 125.11it/s, loss=98.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Avg Loss: 1.5592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100: 100%|██████████| 157/157 [00:01<00:00, 135.66it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Avg Loss: 1.5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100: 100%|██████████| 157/157 [00:01<00:00, 149.91it/s, loss=99.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Avg Loss: 1.5586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100: 100%|██████████| 157/157 [00:01<00:00, 127.24it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Avg Loss: 1.5588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100: 100%|██████████| 157/157 [00:01<00:00, 135.35it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Avg Loss: 1.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100: 100%|██████████| 157/157 [00:01<00:00, 142.56it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Avg Loss: 1.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100: 100%|██████████| 157/157 [00:01<00:00, 137.24it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Avg Loss: 1.5586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100: 100%|██████████| 157/157 [00:01<00:00, 125.52it/s, loss=98.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Avg Loss: 1.5587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100: 100%|██████████| 157/157 [00:01<00:00, 147.17it/s, loss=99.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Avg Loss: 1.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100: 100%|██████████| 157/157 [00:01<00:00, 125.29it/s, loss=99.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Avg Loss: 1.5589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100: 100%|██████████| 157/157 [00:01<00:00, 130.47it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Avg Loss: 1.5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100: 100%|██████████| 157/157 [00:01<00:00, 126.90it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Avg Loss: 1.5575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100: 100%|██████████| 157/157 [00:01<00:00, 146.39it/s, loss=99.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Avg Loss: 1.5571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100: 100%|██████████| 157/157 [00:01<00:00, 146.54it/s, loss=99.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Avg Loss: 1.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100: 100%|██████████| 157/157 [00:01<00:00, 141.27it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Avg Loss: 1.5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100: 100%|██████████| 157/157 [00:01<00:00, 144.51it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Avg Loss: 1.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100: 100%|██████████| 157/157 [00:01<00:00, 139.88it/s, loss=99.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Avg Loss: 1.5568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100: 100%|██████████| 157/157 [00:01<00:00, 134.49it/s, loss=98.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Avg Loss: 1.5558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100: 100%|██████████| 157/157 [00:01<00:00, 130.44it/s, loss=99.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Avg Loss: 1.5560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100: 100%|██████████| 157/157 [00:01<00:00, 130.15it/s, loss=99.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 | Avg Loss: 1.5566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100: 100%|██████████| 157/157 [00:01<00:00, 121.49it/s, loss=98.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 | Avg Loss: 1.5554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100: 100%|██████████| 157/157 [00:01<00:00, 142.83it/s, loss=98.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 | Avg Loss: 1.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100: 100%|██████████| 157/157 [00:01<00:00, 150.74it/s, loss=101] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 | Avg Loss: 1.5559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100: 100%|██████████| 157/157 [00:01<00:00, 131.10it/s, loss=99.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Avg Loss: 1.5554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100: 100%|██████████| 157/157 [00:01<00:00, 135.99it/s, loss=100] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 | Avg Loss: 1.5550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100: 100%|██████████| 157/157 [00:01<00:00, 143.42it/s, loss=98.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Avg Loss: 1.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100: 100%|██████████| 157/157 [00:01<00:00, 130.09it/s, loss=99.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 | Avg Loss: 1.5543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100: 100%|██████████| 157/157 [00:01<00:00, 130.98it/s, loss=98.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 | Avg Loss: 1.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100: 100%|██████████| 157/157 [00:01<00:00, 149.28it/s, loss=99.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Avg Loss: 1.5537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100: 100%|██████████| 157/157 [00:01<00:00, 138.21it/s, loss=99.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Avg Loss: 1.5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100: 100%|██████████| 157/157 [00:01<00:00, 124.56it/s, loss=98.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Avg Loss: 1.5534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100: 100%|██████████| 157/157 [00:01<00:00, 146.16it/s, loss=99.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Avg Loss: 1.5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100: 100%|██████████| 157/157 [00:01<00:00, 138.64it/s, loss=99.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Avg Loss: 1.5530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100: 100%|██████████| 157/157 [00:01<00:00, 128.84it/s, loss=99.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Avg Loss: 1.5533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100: 100%|██████████| 157/157 [00:01<00:00, 129.95it/s, loss=98.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 | Avg Loss: 1.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100: 100%|██████████| 157/157 [00:01<00:00, 127.37it/s, loss=98.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 | Avg Loss: 1.5529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100: 100%|██████████| 157/157 [00:01<00:00, 146.62it/s, loss=98.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 | Avg Loss: 1.5518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100: 100%|██████████| 157/157 [00:01<00:00, 144.01it/s, loss=97.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Avg Loss: 1.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100: 100%|██████████| 157/157 [00:01<00:00, 123.63it/s, loss=98.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Avg Loss: 1.5515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_vae(vae, dataloader, epochs=EPOCHS, lr=LEARNING_RATE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_grid_world(grid):\n",
    "    \"\"\"\n",
    "    Converts a 3-channel grid world into an RGB image for visualization.\n",
    "    - First channel: Wall (0 or 1)\n",
    "    - Second channel: Source (1 if source)\n",
    "    - Third channel: Destination (1 if destination)\n",
    "    \"\"\"\n",
    "    # print(grid[:, :, 0])\n",
    "    wall = grid[:, :, 0] < 0.5\n",
    "    source = grid[:, :, 1] >= 0.5\n",
    "    destination = grid[:, :, 2] >= 0.5\n",
    "    \n",
    "    img = np.ones((*wall.shape, 3), dtype=np.float32)  # White background\n",
    "    \n",
    "    # Set walls to black (0, 0, 0)\n",
    "    img[wall] = np.array([0, 0, 0])\n",
    "    \n",
    "    # Set destination to green (0, 1, 0)\n",
    "    img[destination] = np.array([0, 1, 0])\n",
    "\n",
    "    # Set source to blue (0, 0, 1)\n",
    "    img[source] = np.array([0, 0, 1])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def display_reconstruction(model, dataset, device='cuda', visualize_fn=None, num_samples=5):\n",
    "    \"\"\"\n",
    "    Display discrete original vs reconstructed maze samples from the VAE using predict_discrete_structure.\n",
    "\n",
    "    Args:\n",
    "        model: Trained MazeVAE\n",
    "        dataset: Dataset returning 10x10x3 float32 tensors\n",
    "        device: Device for model + data\n",
    "        visualize_fn: Function to convert 10x10x3 integer array to RGB image\n",
    "        num_samples: Number of maze samples to display\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(3, num_samples, figsize=(3 * num_samples, 8))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            idx = np.random.randint(len(dataset))\n",
    "            maze = dataset[idx].unsqueeze(0).to(torch.float32).to(device)  # shape: (1, 10, 10, 3)\n",
    "            recon, _, _ = model(maze)\n",
    "\n",
    "            # Discretize reconstruction only\n",
    "            discrete_recon = model.predict_discrete_structure(recon).squeeze(0).cpu().numpy()\n",
    "\n",
    "            # Original is already discrete (from dataset)\n",
    "            discrete_input = maze.squeeze(0).cpu().numpy().astype(int)\n",
    "\n",
    "            # Convert to RGB for display\n",
    "            orig_rgb = visualize_fn(discrete_input)\n",
    "            recon_rgb = visualize_fn(discrete_recon)\n",
    "            diff_rgb = np.abs(orig_rgb.astype(float) - recon_rgb.astype(float))\n",
    "\n",
    "            # Plot\n",
    "            axes[0, i].imshow(orig_rgb)\n",
    "            axes[0, i].axis('off')\n",
    "            axes[0, i].set_title(\"Original\")\n",
    "\n",
    "            axes[1, i].imshow(recon_rgb)\n",
    "            axes[1, i].axis('off')\n",
    "            axes[1, i].set_title(\"Reconstructed\")\n",
    "\n",
    "            axes[2, i].imshow(diff_rgb / diff_rgb.max() if diff_rgb.max() > 0 else diff_rgb)\n",
    "            axes[2, i].axis('off')\n",
    "            axes[2, i].set_title(\"Difference\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1896, 0.5283, 0.6680, 0.5776, 0.6343, 0.6163, 0.6814, 0.5477,\n",
      "          0.5961, 0.5350],\n",
      "         [0.6215, 0.5563, 0.6211, 0.3449, 0.3348, 0.4576, 0.3202, 0.3601,\n",
      "          0.5449, 0.6004],\n",
      "         [0.8198, 0.7641, 0.6867, 0.6084, 0.3299, 0.4977, 0.5639, 0.6349,\n",
      "          0.5358, 0.3585],\n",
      "         [0.3285, 0.3658, 0.3481, 0.4447, 0.5113, 0.7544, 0.5746, 0.7723,\n",
      "          0.5920, 0.3852],\n",
      "         [0.4791, 0.5850, 0.7375, 0.6798, 0.4874, 0.6086, 0.3192, 0.7215,\n",
      "          0.6018, 0.4753],\n",
      "         [0.4600, 0.3466, 0.3294, 0.5191, 0.5737, 0.5957, 0.5268, 0.5842,\n",
      "          0.7347, 0.4609],\n",
      "         [0.5250, 0.4897, 0.6726, 0.8719, 0.6645, 0.6581, 0.6814, 0.4481,\n",
      "          0.8579, 0.5130],\n",
      "         [0.6446, 0.4676, 0.4043, 0.5047, 0.4425, 0.4161, 0.4647, 0.4871,\n",
      "          0.4553, 0.4881],\n",
      "         [0.2390, 0.5109, 0.7096, 0.8325, 0.3919, 0.4255, 0.5837, 0.0552,\n",
      "          0.4696, 0.4730],\n",
      "         [0.6726, 0.5792, 0.4405, 0.5616, 0.2717, 0.3503, 0.6332, 0.4450,\n",
      "          0.7611, 0.4901]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 0, 0, 0, 0, 0, 1, 1],\n",
      "         [1, 1, 1, 1, 0, 0, 1, 1, 1, 0],\n",
      "         [0, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
      "         [0, 1, 1, 1, 0, 1, 0, 1, 1, 0],\n",
      "         [0, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
      "         [1, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n",
      "         [1, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
      "         [1, 1, 0, 1, 0, 0, 1, 0, 1, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.6458, 0.3669, 0.6125, 0.3201, 0.3202, 0.6623, 0.4086, 0.7071,\n",
      "          0.4544, 0.4453],\n",
      "         [0.5334, 0.5641, 0.6853, 0.2870, 0.3024, 0.3940, 0.2458, 0.6005,\n",
      "          0.6517, 0.8149],\n",
      "         [0.9134, 0.7952, 0.6909, 0.2960, 0.4336, 0.6900, 0.5633, 0.8214,\n",
      "          0.5114, 0.4191],\n",
      "         [0.5093, 0.7503, 0.6761, 0.4849, 0.6048, 0.7848, 0.4615, 0.7666,\n",
      "          0.6011, 0.4612],\n",
      "         [0.4231, 0.4499, 0.7516, 0.4316, 0.5862, 0.5197, 0.5713, 0.6906,\n",
      "          0.3830, 0.1759],\n",
      "         [0.3824, 0.5947, 0.6397, 0.6335, 0.7776, 0.7219, 0.5432, 0.6246,\n",
      "          0.7436, 0.2792],\n",
      "         [0.5709, 0.5257, 0.5397, 0.3681, 0.4704, 0.6436, 0.4886, 0.3951,\n",
      "          0.4193, 0.3756],\n",
      "         [0.5449, 0.2320, 0.5382, 0.2790, 0.3060, 0.7071, 0.6107, 0.8867,\n",
      "          0.4287, 0.3632],\n",
      "         [0.3989, 0.6802, 0.7359, 0.8343, 0.5356, 0.3899, 0.5086, 0.5559,\n",
      "          0.5536, 0.5098],\n",
      "         [0.5212, 0.3112, 0.4698, 0.6850, 0.2818, 0.2888, 0.4058, 0.4798,\n",
      "          0.3660, 0.3691]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[1, 0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
      "         [1, 1, 1, 0, 0, 0, 0, 1, 1, 1],\n",
      "         [1, 1, 1, 0, 0, 1, 1, 1, 1, 0],\n",
      "         [1, 1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
      "         [0, 0, 1, 0, 1, 1, 1, 1, 0, 0],\n",
      "         [0, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "         [1, 1, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [1, 0, 1, 0, 0, 1, 1, 1, 0, 0],\n",
      "         [0, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
      "         [1, 0, 0, 1, 0, 0, 0, 0, 0, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.3289, 0.5450, 0.4850, 0.6428, 0.7389, 0.6162, 0.8161, 0.6095,\n",
      "          0.5985, 0.6186],\n",
      "         [0.3398, 0.6012, 0.3626, 0.5927, 0.4412, 0.5448, 0.5341, 0.5993,\n",
      "          0.5068, 0.6191],\n",
      "         [0.6884, 0.5876, 0.4086, 0.5739, 0.7194, 0.5770, 0.7414, 0.6917,\n",
      "          0.5446, 0.4710],\n",
      "         [0.6588, 0.5766, 0.5009, 0.5693, 0.5889, 0.5804, 0.7290, 0.8236,\n",
      "          0.4386, 0.4978],\n",
      "         [0.7631, 0.4609, 0.4740, 0.7493, 0.5690, 0.5376, 0.6076, 0.6175,\n",
      "          0.5585, 0.5688],\n",
      "         [0.4548, 0.4768, 0.6246, 0.3632, 0.4497, 0.5091, 0.6842, 0.5341,\n",
      "          0.5622, 0.7230],\n",
      "         [0.6383, 0.4503, 0.6376, 0.3641, 0.6788, 0.7335, 0.5087, 0.6457,\n",
      "          0.7156, 0.7492],\n",
      "         [0.5832, 0.6447, 0.5526, 0.4699, 0.6797, 0.4845, 0.5970, 0.6614,\n",
      "          0.5693, 0.3972],\n",
      "         [0.4588, 0.5308, 0.3321, 0.4730, 0.4619, 0.5707, 0.6168, 0.3483,\n",
      "          0.7110, 0.7874],\n",
      "         [0.6144, 0.4400, 0.4524, 0.5155, 0.6061, 0.5904, 0.6290, 0.4971,\n",
      "          0.4858, 0.4581]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[0, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 1, 0, 1, 0, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 0, 1, 1, 1, 1, 1, 1, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "         [1, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 0, 0, 1, 1, 1, 1, 1],\n",
      "         [1, 0, 1, 0, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
      "         [0, 1, 0, 0, 0, 1, 1, 0, 1, 1],\n",
      "         [1, 0, 0, 1, 1, 1, 1, 0, 0, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.9068, 0.5606, 0.5008, 0.2906, 0.4384, 0.5404, 0.2440, 0.5423,\n",
      "          0.4888, 0.4398],\n",
      "         [0.5733, 0.4274, 0.6945, 0.5783, 0.5189, 0.4606, 0.4676, 0.8498,\n",
      "          0.5915, 0.6366],\n",
      "         [0.5752, 0.4116, 0.6799, 0.4552, 0.5505, 0.6480, 0.3363, 0.4267,\n",
      "          0.6205, 0.5347],\n",
      "         [0.6188, 0.6486, 0.7943, 0.4490, 0.5677, 0.5312, 0.5121, 0.2877,\n",
      "          0.4714, 0.4498],\n",
      "         [0.4304, 0.4247, 0.5174, 0.5735, 0.5829, 0.5209, 0.7129, 0.4008,\n",
      "          0.3303, 0.3839],\n",
      "         [0.6522, 0.6877, 0.6191, 0.8191, 0.5732, 0.7387, 0.5717, 0.5403,\n",
      "          0.4436, 0.3930],\n",
      "         [0.6173, 0.7461, 0.4296, 0.3352, 0.2588, 0.3554, 0.3946, 0.3826,\n",
      "          0.2121, 0.5888],\n",
      "         [0.4272, 0.4767, 0.5035, 0.7540, 0.4358, 0.7501, 0.5382, 0.5345,\n",
      "          0.6125, 0.6699],\n",
      "         [0.7086, 0.6200, 0.5739, 0.4671, 0.6379, 0.5294, 0.5025, 0.9147,\n",
      "          0.4469, 0.7186],\n",
      "         [0.3033, 0.3575, 0.7874, 0.6217, 0.4720, 0.7326, 0.3539, 0.5998,\n",
      "          0.1771, 0.4474]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[1, 1, 1, 0, 0, 1, 0, 1, 0, 0],\n",
      "         [1, 0, 1, 1, 1, 0, 0, 1, 1, 1],\n",
      "         [1, 0, 1, 0, 1, 1, 0, 0, 1, 1],\n",
      "         [1, 1, 1, 0, 1, 1, 1, 0, 0, 0],\n",
      "         [0, 0, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
      "         [0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 0, 1, 1, 1, 1, 0, 1],\n",
      "         [0, 0, 1, 1, 0, 1, 0, 1, 0, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.3950, 0.5450, 0.5002, 0.5586, 0.4634, 0.5555, 0.7283, 0.6924,\n",
      "          0.6134, 0.6991],\n",
      "         [0.5073, 0.4892, 0.6082, 0.5331, 0.3528, 0.3918, 0.5896, 0.2967,\n",
      "          0.4012, 0.4970],\n",
      "         [0.6938, 0.4045, 0.5163, 0.5751, 0.3860, 0.5088, 0.6899, 0.6131,\n",
      "          0.5702, 0.3745],\n",
      "         [0.5704, 0.5971, 0.3883, 0.4743, 0.4249, 0.6340, 0.6519, 0.6679,\n",
      "          0.5453, 0.4376],\n",
      "         [0.5800, 0.6234, 0.6392, 0.5781, 0.3529, 0.3873, 0.5139, 0.4974,\n",
      "          0.3863, 0.4560],\n",
      "         [0.5554, 0.4876, 0.5653, 0.6914, 0.3695, 0.5673, 0.5720, 0.4639,\n",
      "          0.5239, 0.5055],\n",
      "         [0.5221, 0.4042, 0.5645, 0.6764, 0.6218, 0.5606, 0.5368, 0.5401,\n",
      "          0.5762, 0.6654],\n",
      "         [0.4912, 0.5021, 0.5544, 0.7028, 0.4583, 0.5565, 0.3450, 0.2987,\n",
      "          0.5781, 0.2600],\n",
      "         [0.3958, 0.3777, 0.3615, 0.6216, 0.4087, 0.4601, 0.6621, 0.1886,\n",
      "          0.6125, 0.4876],\n",
      "         [0.5314, 0.5057, 0.4337, 0.5722, 0.5119, 0.6201, 0.4939, 0.6643,\n",
      "          0.4982, 0.4700]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[0, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
      "         [1, 0, 1, 1, 0, 0, 1, 0, 0, 0],\n",
      "         [1, 0, 1, 1, 0, 1, 1, 1, 1, 0],\n",
      "         [1, 1, 0, 0, 0, 1, 1, 1, 1, 0],\n",
      "         [1, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
      "         [1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
      "         [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 1, 1, 1, 0, 1, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 1, 0, 0, 1, 0, 1, 0],\n",
      "         [1, 1, 0, 1, 1, 1, 0, 1, 0, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.3237, 0.5007, 0.4278, 0.4389, 0.6366, 0.5720, 0.6982, 0.6665,\n",
      "          0.5169, 0.5985],\n",
      "         [0.2999, 0.4798, 0.5459, 0.5002, 0.2936, 0.4169, 0.4616, 0.3824,\n",
      "          0.3696, 0.5241],\n",
      "         [0.6710, 0.4155, 0.4320, 0.6298, 0.4818, 0.4723, 0.7445, 0.6141,\n",
      "          0.5242, 0.3309],\n",
      "         [0.5258, 0.4950, 0.4470, 0.4061, 0.3017, 0.6123, 0.6127, 0.5747,\n",
      "          0.4282, 0.2744],\n",
      "         [0.6581, 0.5193, 0.4169, 0.4935, 0.4007, 0.4670, 0.5175, 0.4042,\n",
      "          0.1469, 0.5290],\n",
      "         [0.4946, 0.5291, 0.5546, 0.5956, 0.3551, 0.4928, 0.6160, 0.4697,\n",
      "          0.4822, 0.5667],\n",
      "         [0.4748, 0.4757, 0.5120, 0.5130, 0.5226, 0.5045, 0.4505, 0.3807,\n",
      "          0.4779, 0.7487],\n",
      "         [0.5183, 0.4804, 0.4890, 0.7137, 0.3477, 0.5216, 0.3415, 0.2457,\n",
      "          0.6088, 0.2816],\n",
      "         [0.4142, 0.3957, 0.3162, 0.4231, 0.3504, 0.4823, 0.5856, 0.5848,\n",
      "          0.4746, 0.7024],\n",
      "         [0.4178, 0.4388, 0.5981, 0.5222, 0.5926, 0.6209, 0.4727, 0.5362,\n",
      "          0.3624, 0.3573]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[0, 1, 0, 0, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 1, 0, 0, 0, 0, 0, 1],\n",
      "         [1, 0, 0, 1, 0, 0, 1, 1, 1, 0],\n",
      "         [1, 0, 0, 0, 0, 1, 1, 1, 0, 0],\n",
      "         [1, 1, 0, 0, 0, 0, 1, 0, 0, 1],\n",
      "         [0, 1, 1, 1, 0, 0, 1, 0, 0, 1],\n",
      "         [0, 0, 1, 1, 1, 1, 0, 0, 0, 1],\n",
      "         [1, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
      "         [0, 0, 1, 1, 1, 1, 0, 1, 0, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.3908, 0.3891, 0.5735, 0.4156, 0.8393, 0.5787, 0.6301, 0.6236,\n",
      "          0.4213, 0.6871],\n",
      "         [0.3624, 0.4788, 0.6180, 0.3402, 0.4566, 0.5323, 0.2239, 0.4997,\n",
      "          0.5099, 0.4377],\n",
      "         [0.6770, 0.5528, 0.4034, 0.6924, 0.6911, 0.6430, 0.5667, 0.5391,\n",
      "          0.6751, 0.2480],\n",
      "         [0.4014, 0.2765, 0.4740, 0.5042, 0.3729, 0.7493, 0.6674, 0.6766,\n",
      "          0.3795, 0.2826],\n",
      "         [0.7504, 0.4696, 0.2417, 0.6108, 0.6229, 0.6944, 0.5434, 0.4992,\n",
      "          0.1154, 0.7696],\n",
      "         [0.3868, 0.5888, 0.4627, 0.3135, 0.6322, 0.4504, 0.6660, 0.5502,\n",
      "          0.5154, 0.6586],\n",
      "         [0.4977, 0.7175, 0.4823, 0.4949, 0.5885, 0.7809, 0.4664, 0.2626,\n",
      "          0.7310, 0.7607],\n",
      "         [0.7380, 0.7361, 0.5539, 0.7215, 0.2290, 0.5127, 0.6186, 0.3282,\n",
      "          0.6521, 0.5307],\n",
      "         [0.6007, 0.4273, 0.4860, 0.3249, 0.3329, 0.5549, 0.4999, 0.5707,\n",
      "          0.2915, 0.6594],\n",
      "         [0.4451, 0.5296, 0.7092, 0.5273, 0.6144, 0.5958, 0.5830, 0.3201,\n",
      "          0.5682, 0.4269]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[0, 0, 1, 0, 1, 1, 1, 1, 0, 1],\n",
      "         [0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
      "         [1, 1, 0, 1, 1, 1, 1, 1, 1, 0],\n",
      "         [0, 0, 0, 1, 0, 1, 1, 1, 0, 0],\n",
      "         [1, 0, 0, 1, 1, 1, 1, 0, 0, 1],\n",
      "         [0, 1, 0, 0, 1, 0, 1, 1, 1, 1],\n",
      "         [0, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
      "         [1, 1, 1, 1, 0, 1, 1, 0, 1, 1],\n",
      "         [1, 0, 0, 0, 0, 1, 0, 1, 0, 1],\n",
      "         [0, 1, 1, 1, 1, 1, 1, 0, 1, 0]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.5271, 0.6351, 0.4073, 0.5503, 0.6338, 0.5201, 0.7576, 0.4534,\n",
      "          0.5922, 0.2610],\n",
      "         [0.7020, 0.6422, 0.4293, 0.5023, 0.8327, 0.5240, 0.6467, 0.6026,\n",
      "          0.5864, 0.5866],\n",
      "         [0.3582, 0.6128, 0.6367, 0.6303, 0.7988, 0.6735, 0.5375, 0.7217,\n",
      "          0.6141, 0.8139],\n",
      "         [0.7103, 0.7394, 0.6928, 0.5306, 0.7175, 0.4028, 0.4993, 0.6672,\n",
      "          0.6914, 0.8421],\n",
      "         [0.8781, 0.5649, 0.5425, 0.8459, 0.6551, 0.6025, 0.7702, 0.6926,\n",
      "          0.9589, 0.6401],\n",
      "         [0.7239, 0.5755, 0.6753, 0.6347, 0.6263, 0.7119, 0.7152, 0.5334,\n",
      "          0.6744, 0.6442],\n",
      "         [0.7409, 0.7018, 0.6134, 0.5242, 0.4912, 0.3544, 0.4217, 0.8448,\n",
      "          0.6949, 0.2749],\n",
      "         [0.5635, 0.4803, 0.4328, 0.6177, 0.8574, 0.6006, 0.8146, 0.8867,\n",
      "          0.6381, 0.6993],\n",
      "         [0.5224, 0.6887, 0.6837, 0.7460, 0.7094, 0.6283, 0.6360, 0.9104,\n",
      "          0.5457, 0.7224],\n",
      "         [0.6849, 0.4324, 0.6178, 0.7596, 0.4731, 0.5862, 0.6629, 0.8502,\n",
      "          0.7353, 0.7267]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[1, 1, 0, 1, 1, 1, 1, 0, 1, 0],\n",
      "         [1, 1, 0, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 0, 0, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
      "         [1, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 0, 1, 1, 0, 1, 1, 1, 1, 1]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.4713, 0.4413, 0.4746, 0.3698, 0.7633, 0.4639, 0.6693, 0.7259,\n",
      "          0.4352, 0.6974],\n",
      "         [0.5174, 0.5046, 0.5912, 0.4266, 0.7252, 0.4851, 0.4632, 0.2730,\n",
      "          0.4779, 0.3159],\n",
      "         [0.5866, 0.4269, 0.4450, 0.6763, 0.7194, 0.7097, 0.6052, 0.6767,\n",
      "          0.6754, 0.3797],\n",
      "         [0.5898, 0.4780, 0.4937, 0.5545, 0.4238, 0.6577, 0.5755, 0.6346,\n",
      "          0.5558, 0.5969],\n",
      "         [0.7817, 0.5761, 0.2635, 0.5229, 0.5631, 0.5847, 0.7094, 0.4826,\n",
      "          0.4823, 0.7856],\n",
      "         [0.5491, 0.6841, 0.6027, 0.4993, 0.6930, 0.4868, 0.6667, 0.4831,\n",
      "          0.4880, 0.6460],\n",
      "         [0.5316, 0.7836, 0.4022, 0.4137, 0.5349, 0.6651, 0.4224, 0.4439,\n",
      "          0.6233, 0.5069],\n",
      "         [0.5885, 0.7158, 0.6037, 0.8484, 0.3421, 0.6498, 0.6675, 0.4220,\n",
      "          0.6801, 0.4514],\n",
      "         [0.6390, 0.4049, 0.5414, 0.3794, 0.4058, 0.4920, 0.5371, 0.8593,\n",
      "          0.3284, 0.4605],\n",
      "         [0.4367, 0.5546, 0.6702, 0.6595, 0.6655, 0.6358, 0.5290, 0.6653,\n",
      "          0.7033, 0.5659]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[0, 0, 0, 0, 1, 0, 1, 1, 0, 1],\n",
      "         [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
      "         [1, 0, 0, 1, 1, 1, 1, 1, 1, 0],\n",
      "         [1, 0, 0, 1, 0, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 0, 1, 1, 1, 1, 0, 0, 1],\n",
      "         [1, 1, 1, 0, 1, 0, 1, 0, 0, 1],\n",
      "         [1, 1, 0, 0, 1, 1, 0, 0, 1, 1],\n",
      "         [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],\n",
      "         [1, 0, 1, 0, 0, 0, 1, 1, 0, 0],\n",
      "         [0, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], device='cuda:0', dtype=torch.int32)\n",
      "tensor([[[0.5787, 0.3289, 0.7017, 0.7039, 0.3907, 0.6615, 0.6321, 0.2926,\n",
      "          0.6103, 0.6862],\n",
      "         [0.6724, 0.5201, 0.7148, 0.4621, 0.5186, 0.6107, 0.3942, 0.8374,\n",
      "          0.4844, 0.7823],\n",
      "         [0.7367, 0.7044, 0.5329, 0.4892, 0.5462, 0.4889, 0.5627, 0.6022,\n",
      "          0.5625, 0.6783],\n",
      "         [0.5290, 0.5647, 0.5594, 0.6809, 0.6466, 0.5068, 0.4495, 0.6247,\n",
      "          0.6244, 0.5715],\n",
      "         [0.4538, 0.5520, 0.7547, 0.4110, 0.5214, 0.6427, 0.3319, 0.6603,\n",
      "          0.5038, 0.3490],\n",
      "         [0.4452, 0.3967, 0.5998, 0.5882, 0.5893, 0.5838, 0.5999, 0.4713,\n",
      "          0.6789, 0.5552],\n",
      "         [0.5967, 0.4267, 0.6754, 0.8082, 0.7909, 0.6444, 0.6724, 0.5874,\n",
      "          0.6204, 0.7750],\n",
      "         [0.5922, 0.4151, 0.5559, 0.2081, 0.7637, 0.4285, 0.5658, 0.9651,\n",
      "          0.4137, 0.7159],\n",
      "         [0.3887, 0.6583, 0.6172, 0.7218, 0.5494, 0.4659, 0.4968, 0.9287,\n",
      "          0.6810, 0.3941],\n",
      "         [0.6977, 0.4754, 0.1651, 0.4809, 0.6923, 0.4160, 0.7309, 0.2721,\n",
      "          0.4864, 0.5479]]], device='cuda:0')\n",
      "WALL\n",
      "tensor([[[1, 0, 1, 1, 0, 1, 1, 0, 1, 1],\n",
      "         [1, 1, 1, 0, 1, 1, 0, 1, 0, 1],\n",
      "         [1, 1, 1, 0, 1, 0, 1, 1, 1, 1],\n",
      "         [1, 1, 1, 1, 1, 1, 0, 1, 1, 1],\n",
      "         [0, 1, 1, 0, 1, 1, 0, 1, 1, 0],\n",
      "         [0, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n",
      "         [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 0, 1, 0, 1, 0, 1, 1, 0, 1],\n",
      "         [0, 1, 1, 1, 1, 0, 0, 1, 1, 0],\n",
      "         [1, 0, 0, 0, 1, 0, 1, 0, 0, 1]]], device='cuda:0', dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x800 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_reconstruction(model=vae, dataset=dataset, device='cuda', visualize_fn=visualize_grid_world, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class MazeDataset(Dataset):\n",
    "    def __init__(self, root):\n",
    "        self.grid_dir = os.path.join(root, 'grid')\n",
    "        self.path_length_dir = os.path.join(root, 'path_length')\n",
    "        self.astar_dir = os.path.join(root, 'a_star_l2_results')\n",
    "\n",
    "        self.indices = []\n",
    "\n",
    "        for fname in os.listdir(self.grid_dir):\n",
    "            if fname.endswith('.npy'):\n",
    "                idx = fname.split('.')[0].split('_')[-1]\n",
    "                path_file = f'path_length_{idx}.npy'\n",
    "                astar_file = f'a_star_{idx}.npy'\n",
    "\n",
    "                if os.path.exists(os.path.join(self.path_length_dir, path_file)) and \\\n",
    "                   os.path.exists(os.path.join(self.astar_dir, astar_file)):\n",
    "                    self.indices.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indices[i]\n",
    "\n",
    "        # Load grid (maze)\n",
    "        grid_path = os.path.join(self.grid_dir, f'maze_{idx}.npy')\n",
    "        maze = np.load(grid_path)\n",
    "        maze = torch.tensor(maze, dtype=torch.float32)  # assuming [H, W, 3]\n",
    "\n",
    "        # Load scalar values\n",
    "        path_length = np.load(os.path.join(self.path_length_dir, f'path_length_{idx}.npy')).item()\n",
    "        a_star = np.load(os.path.join(self.astar_dir, f'a_star_{idx}.npy')).item()\n",
    "\n",
    "        # Compute difficulty\n",
    "        difficulty = a_star / (max(path_length, 1))\n",
    "        difficulty = torch.tensor(difficulty, dtype=torch.float32)\n",
    "\n",
    "        return maze, difficulty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DiffusionModel(nn.Module):\n",
    "    def __init__(self, latent_dim, cond_dim=1, num_steps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        super(DiffusionModel, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.cond_dim = cond_dim\n",
    "        self.num_steps = num_steps  # Define num_steps here\n",
    "\n",
    "        # Define the noise schedule\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_steps)  # Linear betas\n",
    "        self.alphas = 1.0 - self.betas  # Alpha = 1 - Beta\n",
    "        self.alpha_bars = torch.cumprod(self.alphas, dim=0)  # Cumulative product for alpha\n",
    "\n",
    "        # Define your model network\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim + cond_dim + 1, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t, cond):\n",
    "        \"\"\"\n",
    "        :param x: The latent vector at time step t (e.g., the noisy version)\n",
    "        :param t: The current time step (integer)\n",
    "        :param cond: The conditioning information (e.g., difficulty)\n",
    "        \"\"\"\n",
    "        t = t.float().unsqueeze(1) / self.num_steps  # Normalize time step to [0, 1]\n",
    "        input = torch.cat([x, cond, t], dim=1)  # Concatenate latent, condition, and time\n",
    "        return self.model(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 1e-4\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "class LatentDiffusionTrainer:\n",
    "    def __init__(self, model, latent_dim, timesteps=1000, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.timesteps = timesteps\n",
    "        self.device = device\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.betas = linear_beta_schedule(timesteps).to(device)\n",
    "        self.alphas = 1. - self.betas\n",
    "        self.alpha_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "\n",
    "    def q_sample(self, x_start, t, noise=None):\n",
    "        # forward diffusion: q(x_t | x_0)\n",
    "        if noise is None:\n",
    "            noise = torch.randn_like(x_start)\n",
    "        sqrt_alpha_cumprod = self.alpha_cumprod[t].sqrt().unsqueeze(1)\n",
    "        sqrt_one_minus = (1 - self.alpha_cumprod[t]).sqrt().unsqueeze(1)\n",
    "        return sqrt_alpha_cumprod * x_start + sqrt_one_minus * noise\n",
    "\n",
    "    def p_losses(self, x_start, cond, t):\n",
    "        noise = torch.randn_like(x_start)\n",
    "        x_noisy = self.q_sample(x_start, t, noise)\n",
    "        noise_pred = self.model(x_noisy, t, cond)\n",
    "        return F.mse_loss(noise_pred, noise)\n",
    "\n",
    "    def train_step(self, x, cond, optimizer):\n",
    "        self.model.train()\n",
    "        t = torch.randint(0, self.timesteps, (x.size(0),), device=x.device)\n",
    "        loss = self.p_losses(x, cond, t)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "vae.eval()\n",
    "\n",
    "def train_diffusion(model, trainer, dataloader, epochs=10, lr=1e-4):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for grid, difficulty in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "            grid = grid.to(torch.float32).to(trainer.device)\n",
    "            mu, logvar = vae.encode(grid)\n",
    "            latent = vae.reparameterize(mu, logvar)\n",
    "            difficulty = difficulty.to(trainer.device).unsqueeze(1)  # [B, 1]\n",
    "            loss = trainer.train_step(latent, difficulty, optimizer)\n",
    "            total_loss += loss\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 157/157 [00:01<00:00, 102.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.9824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 157/157 [00:01<00:00, 110.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.9083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 157/157 [00:01<00:00, 114.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.8047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 157/157 [00:01<00:00, 112.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 0.7192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 157/157 [00:01<00:00, 91.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 0.6526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 157/157 [00:01<00:00, 105.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.5980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 157/157 [00:01<00:00, 104.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.5542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 157/157 [00:01<00:00, 108.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.5166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 157/157 [00:01<00:00, 108.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.4888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 157/157 [00:01<00:00, 113.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 157/157 [00:01<00:00, 112.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Loss: 0.4393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 157/157 [00:01<00:00, 111.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Loss: 0.4323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 157/157 [00:01<00:00, 97.58it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Loss: 0.4249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 157/157 [00:01<00:00, 113.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Loss: 0.4082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 157/157 [00:01<00:00, 115.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Loss: 0.3982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 157/157 [00:01<00:00, 110.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Loss: 0.3891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 157/157 [00:01<00:00, 107.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Loss: 0.3811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 157/157 [00:01<00:00, 105.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Loss: 0.3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 157/157 [00:01<00:00, 107.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Loss: 0.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 157/157 [00:01<00:00, 109.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Loss: 0.3798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 157/157 [00:01<00:00, 106.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 Loss: 0.3680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 157/157 [00:01<00:00, 108.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 Loss: 0.3678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 157/157 [00:01<00:00, 111.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 Loss: 0.3673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 157/157 [00:01<00:00, 110.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 Loss: 0.3718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 157/157 [00:01<00:00, 112.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 Loss: 0.3558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 157/157 [00:01<00:00, 108.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 Loss: 0.3616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 157/157 [00:01<00:00, 104.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 Loss: 0.3528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 157/157 [00:01<00:00, 106.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 Loss: 0.3668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 157/157 [00:01<00:00, 108.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 Loss: 0.3638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 157/157 [00:01<00:00, 105.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 Loss: 0.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 157/157 [00:01<00:00, 94.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 Loss: 0.3640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 157/157 [00:01<00:00, 108.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 Loss: 0.3595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 157/157 [00:01<00:00, 102.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 Loss: 0.3593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 157/157 [00:01<00:00, 104.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 Loss: 0.3523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 157/157 [00:01<00:00, 107.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 Loss: 0.3529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 157/157 [00:01<00:00, 97.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 Loss: 0.3583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 157/157 [00:01<00:00, 95.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 Loss: 0.3502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 157/157 [00:01<00:00, 104.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 Loss: 0.3566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 157/157 [00:01<00:00, 103.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 Loss: 0.3496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 157/157 [00:01<00:00, 105.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 Loss: 0.3544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 157/157 [00:01<00:00, 103.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 Loss: 0.3463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 157/157 [00:01<00:00, 101.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 Loss: 0.3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 157/157 [00:01<00:00, 102.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 Loss: 0.3569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 157/157 [00:01<00:00, 93.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 Loss: 0.3479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 157/157 [00:01<00:00, 89.96it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 Loss: 0.3516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 157/157 [00:01<00:00, 105.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 Loss: 0.3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 157/157 [00:01<00:00, 104.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 Loss: 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 157/157 [00:01<00:00, 94.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 Loss: 0.3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 157/157 [00:01<00:00, 107.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 Loss: 0.3497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 157/157 [00:01<00:00, 104.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 Loss: 0.3484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51: 100%|██████████| 157/157 [00:01<00:00, 105.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 Loss: 0.3441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52: 100%|██████████| 157/157 [00:01<00:00, 106.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 Loss: 0.3470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53: 100%|██████████| 157/157 [00:01<00:00, 107.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 Loss: 0.3501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54: 100%|██████████| 157/157 [00:01<00:00, 107.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 Loss: 0.3529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55: 100%|██████████| 157/157 [00:01<00:00, 104.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 Loss: 0.3428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56: 100%|██████████| 157/157 [00:01<00:00, 97.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 Loss: 0.3498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57: 100%|██████████| 157/157 [00:01<00:00, 90.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 Loss: 0.3423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58: 100%|██████████| 157/157 [00:01<00:00, 103.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 Loss: 0.3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59: 100%|██████████| 157/157 [00:01<00:00, 123.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 Loss: 0.3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60: 100%|██████████| 157/157 [00:01<00:00, 119.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 Loss: 0.3412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61: 100%|██████████| 157/157 [00:01<00:00, 101.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 Loss: 0.3413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62: 100%|██████████| 157/157 [00:01<00:00, 103.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 Loss: 0.3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63: 100%|██████████| 157/157 [00:01<00:00, 103.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 Loss: 0.3414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64: 100%|██████████| 157/157 [00:01<00:00, 86.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 Loss: 0.3422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65: 100%|██████████| 157/157 [00:01<00:00, 89.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 Loss: 0.3432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66: 100%|██████████| 157/157 [00:01<00:00, 82.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 Loss: 0.3386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67: 100%|██████████| 157/157 [00:01<00:00, 94.22it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 Loss: 0.3407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68: 100%|██████████| 157/157 [00:01<00:00, 91.16it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 Loss: 0.3381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69: 100%|██████████| 157/157 [00:01<00:00, 92.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 Loss: 0.3430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70: 100%|██████████| 157/157 [00:01<00:00, 95.71it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 Loss: 0.3467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71: 100%|██████████| 157/157 [00:01<00:00, 95.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 Loss: 0.3395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72: 100%|██████████| 157/157 [00:01<00:00, 98.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 Loss: 0.3468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73: 100%|██████████| 157/157 [00:01<00:00, 93.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 Loss: 0.3428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74: 100%|██████████| 157/157 [00:01<00:00, 101.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 Loss: 0.3439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75: 100%|██████████| 157/157 [00:01<00:00, 106.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 Loss: 0.3372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76: 100%|██████████| 157/157 [00:01<00:00, 105.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 Loss: 0.3340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77: 100%|██████████| 157/157 [00:01<00:00, 102.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 Loss: 0.3389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78: 100%|██████████| 157/157 [00:01<00:00, 105.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 Loss: 0.3348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79: 100%|██████████| 157/157 [00:01<00:00, 103.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 Loss: 0.3348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80: 100%|██████████| 157/157 [00:01<00:00, 103.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 Loss: 0.3380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81: 100%|██████████| 157/157 [00:01<00:00, 107.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 Loss: 0.3374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82: 100%|██████████| 157/157 [00:01<00:00, 100.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 Loss: 0.3447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83: 100%|██████████| 157/157 [00:01<00:00, 97.39it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 Loss: 0.3361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84: 100%|██████████| 157/157 [00:01<00:00, 90.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 Loss: 0.3415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85: 100%|██████████| 157/157 [00:01<00:00, 98.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 Loss: 0.3399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86: 100%|██████████| 157/157 [00:01<00:00, 98.56it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 Loss: 0.3342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87: 100%|██████████| 157/157 [00:01<00:00, 103.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 Loss: 0.3363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88: 100%|██████████| 157/157 [00:01<00:00, 102.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 Loss: 0.3361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89: 100%|██████████| 157/157 [00:01<00:00, 102.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 Loss: 0.3388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90: 100%|██████████| 157/157 [00:01<00:00, 104.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 Loss: 0.3399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91: 100%|██████████| 157/157 [00:01<00:00, 103.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 Loss: 0.3313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92: 100%|██████████| 157/157 [00:01<00:00, 107.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 Loss: 0.3353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93: 100%|██████████| 157/157 [00:01<00:00, 106.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 Loss: 0.3396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94: 100%|██████████| 157/157 [00:01<00:00, 108.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 Loss: 0.3393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95: 100%|██████████| 157/157 [00:01<00:00, 109.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 Loss: 0.3334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96: 100%|██████████| 157/157 [00:01<00:00, 105.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 Loss: 0.3317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97: 100%|██████████| 157/157 [00:01<00:00, 107.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 Loss: 0.3313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98: 100%|██████████| 157/157 [00:01<00:00, 111.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 Loss: 0.3318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 157/157 [00:01<00:00, 107.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 Loss: 0.3319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100: 100%|██████████| 157/157 [00:01<00:00, 103.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 Loss: 0.3282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "latent_dim = LATENT_DIM \n",
    "diffusionMLP = DiffusionModel(latent_dim)\n",
    "trainer = LatentDiffusionTrainer(diffusionMLP, latent_dim, timesteps=1000)\n",
    "\n",
    "maze_dataset = MazeDataset(\"/home/atul/diffusion-based-environment-generator/generator/data/\")\n",
    "diffusion_dataloader = torch.utils.data.DataLoader(maze_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "train_diffusion(diffusionMLP, trainer, diffusion_dataloader, epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_diffusion(diffusion_model, vae, difficulty, latent_dim, device='cuda'):\n",
    "    diffusion_model.eval()\n",
    "    vae.eval()\n",
    "\n",
    "    # Start from random noise in latent space\n",
    "    x = torch.randn(1, latent_dim).to(device)  # shape [1, latent_dim]\n",
    "    cond = difficulty.view(1, 1).to(device)    # shape [1, 1]\n",
    "\n",
    "    # Run diffusion sampling loop (reverse process)\n",
    "    for t in reversed(range(diffusion_model.num_steps)):\n",
    "        t_tensor = torch.full((1,), t, dtype=torch.long, device=device)\n",
    "        eps_theta = diffusion_model(x, t_tensor, cond)\n",
    "        alpha_t = diffusion_model.alphas[t]\n",
    "        alpha_bar_t = diffusion_model.alpha_bars[t]\n",
    "        beta_t = diffusion_model.betas[t]\n",
    "\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x)\n",
    "        else:\n",
    "            noise = 0\n",
    "\n",
    "        x = (1 / torch.sqrt(alpha_t)) * (\n",
    "            x - ((1 - alpha_t) / torch.sqrt(1 - alpha_bar_t)) * eps_theta\n",
    "        ) + torch.sqrt(beta_t) * noise\n",
    "\n",
    "    # Decode the final latent vector into a maze\n",
    "    with torch.no_grad():\n",
    "        recon = vae.decode(x).view(1, 10, 10, 3).cpu()\n",
    "        discrete_struct = vae.predict_discrete_structure(recon).squeeze(0).cpu().numpy()\n",
    "\n",
    "    return discrete_struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(sample, difficulty):\n",
    "    img = visualize_grid_world(sample)\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Sampled Maze — Difficulty {difficulty.item():.2f}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6573, 0.4743, 0.7238, 0.8655, 0.6143, 0.7014, 0.7699, 0.3276,\n",
      "          0.8402, 0.7250],\n",
      "         [0.6922, 0.4255, 0.7058, 0.7224, 0.5550, 0.7517, 0.7193, 0.5754,\n",
      "          0.3712, 0.6769],\n",
      "         [0.7139, 0.5999, 0.5079, 0.7673, 0.4894, 0.1657, 0.7121, 0.3629,\n",
      "          0.6045, 0.5260],\n",
      "         [0.4516, 0.3336, 0.5396, 0.6426, 0.6129, 0.3761, 0.5220, 0.4178,\n",
      "          0.5002, 0.3500],\n",
      "         [0.1370, 0.6303, 0.6934, 0.3705, 0.4403, 0.5844, 0.1792, 0.6814,\n",
      "          0.2193, 0.6322],\n",
      "         [0.4285, 0.3303, 0.5412, 0.5420, 0.2881, 0.3643, 0.5059, 0.5741,\n",
      "          0.5010, 0.5693],\n",
      "         [0.3734, 0.4285, 0.8278, 0.9506, 0.8689, 0.4791, 0.8593, 0.4656,\n",
      "          0.9200, 0.9325],\n",
      "         [0.6339, 0.5389, 0.5995, 0.2505, 0.8699, 0.2997, 0.2889, 0.8404,\n",
      "          0.4331, 0.7506],\n",
      "         [0.2771, 0.3609, 0.7236, 0.5842, 0.6044, 0.5544, 0.5832, 0.9617,\n",
      "          0.7015, 0.5327],\n",
      "         [0.7261, 0.7235, 0.3506, 0.4712, 0.7398, 0.6218, 0.7520, 0.2050,\n",
      "          0.4280, 0.6719]]])\n",
      "WALL\n",
      "tensor([[[1, 0, 1, 1, 1, 1, 1, 0, 1, 1],\n",
      "         [1, 0, 1, 1, 1, 1, 1, 1, 0, 1],\n",
      "         [1, 1, 1, 1, 0, 0, 1, 0, 1, 1],\n",
      "         [0, 0, 1, 1, 1, 0, 1, 0, 1, 0],\n",
      "         [0, 1, 1, 0, 0, 1, 0, 1, 0, 1],\n",
      "         [0, 0, 1, 1, 0, 0, 1, 1, 1, 1],\n",
      "         [0, 0, 1, 1, 1, 0, 1, 0, 1, 1],\n",
      "         [1, 1, 1, 0, 1, 0, 0, 1, 0, 1],\n",
      "         [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
      "         [1, 1, 0, 0, 1, 1, 1, 0, 0, 1]]], dtype=torch.int32)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "difficulty = torch.tensor([1.0])  # Or any difficulty level you want\n",
    "sampled_maze = sample_from_diffusion(diffusionMLP, vae, difficulty, latent_dim=vae.latent_dim)\n",
    "visualize_sample(sampled_maze, difficulty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
