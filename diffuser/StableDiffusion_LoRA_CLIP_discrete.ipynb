{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "af842a4b-30e4-469d-b315-e5405730df14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af842a4b-30e4-469d-b315-e5405730df14",
        "outputId": "27b5603e-40f4-41f7-ef12-76808f966178"
      },
      "outputs": [],
      "source": [
        "# !pip install einops torch maze-dataset --q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cfa8f76c-2435-45e0-92af-e1c548bf0390",
      "metadata": {
        "id": "cfa8f76c-2435-45e0-92af-e1c548bf0390"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from torch.nn import functional as F\n",
        "\n",
        "now = datetime.now()\n",
        "formatted_time = now.strftime(\"%Y%m%d_%H%M%S\")\n",
        "loss_curves_folder = f\"../data/loss_curves_{formatted_time}/stable_diffusion_diffusion_models\"\n",
        "# loss_curves_folder = f\"../data/lora_tests\"\n",
        "if not os.path.exists(loss_curves_folder):\n",
        "    os.makedirs(loss_curves_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "bf0f5bb1-2c86-4f19-bafe-7b7bec3a57ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf0f5bb1-2c86-4f19-bafe-7b7bec3a57ff",
        "outputId": "5d16aa39-38b8-429f-f379-7d699ed534cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /Users/I749793/Desktop/NUS/CS5340 - Uncertainty Modeling in AI/project/diffusion-based-environment-generator\n"
          ]
        }
      ],
      "source": [
        "os.chdir(\"..\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "543d1c3c-8f5e-403d-b9a1-ce031a9587c7",
      "metadata": {
        "id": "543d1c3c-8f5e-403d-b9a1-ce031a9587c7"
      },
      "source": [
        "## Loading the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e7448583-863f-4043-9e54-c36788bf8b30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7448583-863f-4043-9e54-c36788bf8b30",
        "outputId": "3833d816-19ce-4bde-fce1-8c6d53584d7a",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from generator.maze.grid_world_generator import generate_multiple_grid_worlds\n",
        "from generator.maze.solvers.a_star_l1 import main as a_star_l1_paths\n",
        "from generator.maze.solvers.bfs import main as bfs_paths\n",
        "\n",
        "# parent_directory = \"./data\"\n",
        "# if not os.path.exists(parent_directory):\n",
        "#     os.makedirs(parent_directory)\n",
        "# # generates the mazes\n",
        "# mazes = generate_multiple_grid_worlds(num_worlds=25000, parent_directory=parent_directory)\n",
        "# # generate path travrsals\n",
        "# a_star_l1_paths(parent_directory)\n",
        "# bfs_paths(parent_directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6407b36e-2b1a-49da-8fda-dc83f7bb3481",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6407b36e-2b1a-49da-8fda-dc83f7bb3481",
        "outputId": "e65862df-98a3-4d88-9261-c7466ce34052"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch.utils.data import Dataset\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# def preprocess_image(image, target_size=32):\n",
        "#     image = np.array(image)\n",
        "\n",
        "#     scale_factor = target_size // image.shape[0]\n",
        "#     image = np.kron(image, np.ones((scale_factor, scale_factor, 1)))\n",
        "\n",
        "#     image = image.astype(np.float32) / 127.5 - 1\n",
        "#     image = torch.tensor(image).permute(2, 0, 1)\n",
        "#     return image\n",
        "\n",
        "# def load_dataset_from_npy(directory=\"./data\", target_size=32):\n",
        "#     images = []\n",
        "#     path_lengths = []\n",
        "\n",
        "#     files = sorted([f for f in os.listdir(directory) if f.endswith(\".npy\")])\n",
        "\n",
        "#     for file in files:\n",
        "#         img = np.load(os.path.join(directory, file))\n",
        "\n",
        "#         mask = np.all(img == [0, 0, 255], axis=-1)\n",
        "#         img[mask] = [255, 255, 255]\n",
        "#         img = img[:-1, :-1]\n",
        "\n",
        "#         image = preprocess_image(img, target_size)\n",
        "\n",
        "#         base_name = os.path.splitext(file)[0]\n",
        "#         len_filename = base_name + \"_len.txt\"\n",
        "#         len_path = os.path.join(directory, len_filename)\n",
        "\n",
        "#         with open(len_path, \"r\") as f:\n",
        "#             maze_length = int(f.read().strip())\n",
        "\n",
        "#         images.append(image)\n",
        "#         path_lengths.append(maze_length)\n",
        "\n",
        "#     return images, path_lengths\n",
        "\n",
        "# images, path_lengths = load_dataset_from_npy(\"./data\", target_size=32)\n",
        "\n",
        "# plt.imshow(images[0].permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "83a74713",
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess_image(image, target_size=32):\n",
        "    image = np.array(image)\n",
        "    scale_factor = target_size // image.shape[0] \n",
        "    # image = np.kron(image, np.ones((scale_factor, scale_factor, 1))) \n",
        "    \n",
        "    # image = image.astype(np.float32) / 127.5 - 1\n",
        "    image = image.astype(np.float32)\n",
        "    image = torch.tensor(image).permute(2, 0, 1)\n",
        "    image = F.interpolate(image.unsqueeze(0), size=(target_size, target_size), mode='nearest').squeeze(0)  # (3, 32, 32)\n",
        "\n",
        "    return image\n",
        "\n",
        "def plot_grid_world(grid):\n",
        "    \"\"\"\n",
        "    Plots the given grid world.\n",
        "    \"\"\"\n",
        "    wall = grid[:,:,0] == 0\n",
        "    source = grid[:,:,1] == 1\n",
        "    destination = grid[:,:,2] == 1\n",
        "\n",
        "    img = np.ones((*wall.shape, 3), dtype=np.float32)  # White background\n",
        "    img[wall] = np.array([0, 0, 0])  # Walls → Black\n",
        "    img[source] = np.array([1, 0, 0])  # Source → Red\n",
        "    img[destination] = np.array([0, 1, 0])  # Destination → Green\n",
        "\n",
        "    return img\n",
        "\n",
        "def load_dataset_from_npy(parent_directory=\"./data\", target_size=32):\n",
        "    images = []\n",
        "    path_lengths = []\n",
        "    num_nodes_traversed_astar = []\n",
        "    num_nodes_traversed_bfs = []\n",
        "    \n",
        "    mazes_directory = os.path.join(parent_directory, \"mazes\")\n",
        "    files = sorted([f for f in os.listdir(mazes_directory) if f.endswith(\".npy\")])\n",
        "    \n",
        "    for file in files:\n",
        "        img = np.load(os.path.join(mazes_directory, file))\n",
        "        if(img.shape != (10,10,3)):\n",
        "            continue\n",
        "        # mask = np.all(img == [0, 0, 255], axis=-1)\n",
        "        # img[mask] = [255, 255, 255]\n",
        "        # img = img[:-1, :-1]\n",
        "        # image = preprocess_image(img, target_size)\n",
        "\n",
        "        image = plot_grid_world(img)\n",
        "        mask = np.all(image == [0, 0, 255], axis=-1)\n",
        "        image[mask] = [255, 255, 255]\n",
        "        image = preprocess_image(image, target_size)\n",
        "\n",
        "        pattern = r'maze_(\\d+)'\n",
        "        match = re.search(pattern, file)\n",
        "        num = 0\n",
        "        if match:\n",
        "            num = int(match.group(1))\n",
        "        else:\n",
        "            continue\n",
        "        \n",
        "        # base_name = os.path.splitext(file)[0]\n",
        "        # len_filename = base_name + \"_len.txt\"\n",
        "        len_filename = f\"path_length_{num}\" + \".npy\"\n",
        "        len_path = os.path.join(mazes_directory, len_filename)\n",
        "        astar_traversal_filename = f\"a_star_{num}\" + \".npy\"\n",
        "        astar_traversal_path = os.path.join(parent_directory, \"a_star_l1_results\" ,astar_traversal_filename)\n",
        "        bfs_traversal_filename = f\"bfs_{num}\" + \".npy\"\n",
        "        bfs_traversal_path = os.path.join(parent_directory, \"bfs_results\" ,bfs_traversal_filename)\n",
        "        \n",
        "        # with open(len_path, \"r\") as f:\n",
        "        #     maze_length = int(f.read().strip())\n",
        "        maze_length = np.load(len_path)\n",
        "        astar_traversal = np.load(astar_traversal_path)\n",
        "        bfs_traversal = np.load(bfs_traversal_path)\n",
        "        \n",
        "        images.append(image)\n",
        "        path_lengths.append(int(maze_length))\n",
        "        num_nodes_traversed_astar.append(int(astar_traversal))\n",
        "        num_nodes_traversed_bfs.append(int(bfs_traversal))\n",
        "    \n",
        "    return images, path_lengths, num_nodes_traversed_astar, num_nodes_traversed_bfs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "73f89a5f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# mazes_data_path = \"./data/\"\n",
        "# images, org_path_lengths, num_nodes_astar, num_nodes_bfs = load_dataset_from_npy(mazes_data_path, target_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "9364d0ee",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plt.imshow(images[0].permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# plt.axis('off')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "e2a04378-6293-4c79-95d0-fa6e305cba28",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2a04378-6293-4c79-95d0-fa6e305cba28",
        "outputId": "1e1d158e-a42a-453d-ea90-ff6a716979fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current working directory: /Users/I749793/Desktop/NUS/CS5340 - Uncertainty Modeling in AI/project/diffusion-based-environment-generator/diffuser\n"
          ]
        }
      ],
      "source": [
        "# print(f\"Current working directory: {os.getcwd()}\")\n",
        "os.chdir(\"./diffuser\")\n",
        "print(f\"Current working directory: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "742a775a-18e1-4d73-a304-0d951dfc05c2",
      "metadata": {
        "id": "742a775a-18e1-4d73-a304-0d951dfc05c2",
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "### VAE Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0b8328c6-fdf1-4599-9140-b1ee9c6cc029",
      "metadata": {
        "id": "0b8328c6-fdf1-4599-9140-b1ee9c6cc029"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "335fe85b-942c-4707-89fe-fd5e10b8214d",
      "metadata": {
        "id": "335fe85b-942c-4707-89fe-fd5e10b8214d"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 1e-4\n",
        "EPOCHS = 100\n",
        "LATENT_CHANNELS = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f1bd601d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# class MazeTensorDataset(Dataset):\n",
        "#     def __init__(self, images, path_lengths, num_nodes_astar, num_nodes_bfs):\n",
        "#         self.images = images\n",
        "#         self.path_lengths = path_lengths\n",
        "#         self.num_nodes_astar = num_nodes_astar\n",
        "#         self.num_nodes_bfs = num_nodes_bfs\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return len(self.images)\n",
        "    \n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.images[idx], self.path_lengths[idx], self.num_nodes_astar[idx], self.num_nodes_bfs[idx]\n",
        "    \n",
        "class MazeTensorDataset(Dataset):\n",
        "    def __init__(self, images, path_lengths, num_nodes_astar, num_nodes_bfs):\n",
        "        self.images = images\n",
        "        self.path_lengths = path_lengths\n",
        "        self.num_nodes_astar = num_nodes_astar\n",
        "        self.num_nodes_bfs = num_nodes_bfs\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        prompt = \"a maze with path length \" + str(self.path_lengths[idx]) + \", and number of nodes traversed using astar algorithm \" + str(self.num_nodes_astar[idx])\n",
        "        return self.images[idx], prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "5984963c-d4d5-402c-bae4-4b79276425f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5984963c-d4d5-402c-bae4-4b79276425f3",
        "outputId": "0c7d727d-5507-4e0b-c336-168d6ced665b"
      },
      "outputs": [],
      "source": [
        "# print(\"Total images:\", len(images))\n",
        "# print(\"Total path_lengths:\", len(path_lengths))\n",
        "\n",
        "# total = len(images)\n",
        "# test_size = int(0.2 * total)\n",
        "# all_indices = list(range(total))\n",
        "# random.shuffle(all_indices)\n",
        "\n",
        "# test_indices = all_indices[:test_size]\n",
        "# train_indices = all_indices[test_size:]\n",
        "\n",
        "# train_images = [images[i] for i in train_indices]\n",
        "# train_path_lengths = [path_lengths[i] for i in train_indices]\n",
        "\n",
        "# test_images = [images[i] for i in test_indices]\n",
        "# test_path_lengths = [path_lengths[i] for i in test_indices]\n",
        "\n",
        "# dataset = MazeTensorDataset(train_images, train_path_lengths)\n",
        "# test_dataset = MazeTensorDataset(test_images, test_path_lengths)\n",
        "\n",
        "# print(\"Train dataset length:\", len(dataset))\n",
        "# print(\"Test dataset length:\", len(test_dataset))\n",
        "\n",
        "# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# unique_train_paths = set(train_path_lengths)\n",
        "# print(\"Unique training path lengths:\", unique_train_paths)\n",
        "# print(\"Number of unique training paths:\", len(unique_train_paths))\n",
        "\n",
        "# unique_test_paths = set(test_path_lengths)\n",
        "# print(\"Unique test path lengths:\", unique_test_paths)\n",
        "# print(\"Number of unique test paths:\", len(unique_test_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "960b6cda",
      "metadata": {},
      "outputs": [],
      "source": [
        "# path_lengths = org_path_lengths\n",
        "\n",
        "# ## use the scaled path lengths based on the number of nodes traversed\n",
        "# # path_lengths = [a / b if b!=0 else a for a, b in zip(path_lengths, num_nodes_astar)]\n",
        "# # path_lengths = [a / b if b!=0 else a for a, b in zip(path_lengths, num_nodes_bfs)]\n",
        "\n",
        "# print(\"Total images:\", len(images))\n",
        "# print(\"Total path_lengths:\", len(path_lengths))\n",
        "\n",
        "# total = len(images)\n",
        "# test_size = int(0.2 * total)\n",
        "# all_indices = list(range(total))\n",
        "# random.shuffle(all_indices)\n",
        "\n",
        "# test_indices = all_indices[:test_size]\n",
        "# train_indices = all_indices[test_size:]\n",
        "\n",
        "# train_images = [images[i] for i in train_indices]\n",
        "# train_path_lengths = [path_lengths[i] for i in train_indices]\n",
        "# train_num_nodes_astar = [num_nodes_astar[i] for i in train_indices]\n",
        "# train_num_nodes_bfs = [num_nodes_bfs[i] for i in train_indices]\n",
        "\n",
        "# test_images = [images[i] for i in test_indices]\n",
        "# test_path_lengths = [path_lengths[i] for i in test_indices]\n",
        "# test_num_nodes_astar = [num_nodes_astar[i] for i in test_indices]\n",
        "# test_num_nodes_bfs = [num_nodes_bfs[i] for i in test_indices]\n",
        "\n",
        "# dataset = MazeTensorDataset(train_images, train_path_lengths, train_num_nodes_astar, train_num_nodes_bfs)\n",
        "# test_dataset = MazeTensorDataset(test_images, test_path_lengths, test_num_nodes_astar, test_num_nodes_bfs)\n",
        "\n",
        "# print(\"Train dataset length:\", len(dataset))\n",
        "# print(\"Test dataset length:\", len(test_dataset))\n",
        "\n",
        "# dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# unique_train_paths = set(train_path_lengths)\n",
        "# print(\"Unique training path lengths:\", unique_train_paths)\n",
        "# print(\"Number of unique training paths:\", len(unique_train_paths))\n",
        "\n",
        "# unique_test_paths = set(test_path_lengths)\n",
        "# print(\"Unique test path lengths:\", unique_test_paths)\n",
        "# print(\"Number of unique test paths:\", len(unique_test_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "0e98f779",
      "metadata": {},
      "outputs": [],
      "source": [
        "# import safetensors\n",
        "# print(safetensors.__file__)\n",
        "\n",
        "# from safetensors.torch import save_file, load_file\n",
        "# print(\"Success!\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class MazeDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.grid_dir = os.path.join(root, 'mazes')\n",
        "        self.path_length_dir = os.path.join(root, 'mazes')\n",
        "        self.astar_dir = os.path.join(root, 'a_star_l1_results')\n",
        "\n",
        "        self.indices = []\n",
        "\n",
        "        for fname in os.listdir(self.grid_dir):\n",
        "            if fname.endswith('.npy') and fname.startswith('maze_'):\n",
        "                idx = fname.split('.')[0].split('_')[-1]\n",
        "                path_file = f'path_length_{idx}.npy'\n",
        "                astar_file = f'a_star_{idx}.npy'\n",
        "\n",
        "                if os.path.exists(os.path.join(self.path_length_dir, path_file)) and \\\n",
        "                   os.path.exists(os.path.join(self.astar_dir, astar_file)):\n",
        "                    self.indices.append(idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        idx = self.indices[i]\n",
        "\n",
        "        # Load grid (maze)\n",
        "        grid_path = os.path.join(self.grid_dir, f'maze_{idx}.npy')\n",
        "        maze = np.load(grid_path)\n",
        "        maze = torch.tensor(maze, dtype=torch.float32)  # assuming [H, W, 3]\n",
        "        maze = maze.permute(2, 0, 1)\n",
        "\n",
        "        # Load scalar values\n",
        "        path_length = np.load(os.path.join(self.path_length_dir, f'path_length_{idx}.npy')).item()\n",
        "        a_star = np.load(os.path.join(self.astar_dir, f'a_star_{idx}.npy')).item()\n",
        "\n",
        "        # Compute difficulty\n",
        "        difficulty = a_star / (max(path_length, 1))\n",
        "        difficulty = torch.tensor(difficulty, dtype=torch.float32)\n",
        "        prompt = f\"a maze with difficulty {difficulty.item()}\"\n",
        "        return maze, prompt\n",
        "\n",
        "\n",
        "current_directory = os.getcwd()\n",
        "mazes_data_path = os.path.join(os.path.dirname(current_directory), \"data\")\n",
        "dataset = MazeDataset(root=mazes_data_path)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "37e80c38",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from diffusers import AutoencoderKL\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load Stable Diffusion's pre-trained VAE\n",
        "vae = AutoencoderKL.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"vae\").to(device)\n",
        "# vae_checkpoint = torch.load(\"/Users/I749793/Desktop/NUS/CS5340 - Uncertainty Modeling in AI/project/diffusion-based-environment-generator/data/stablediffusion_weights.pth\", map_location=device)  # or \"cuda\" if you want\n",
        "# vae_checkpoint = torch.load(\"../data/vae_models/stablediffusion_vae_weights.pth\", map_location=device)  # or \"cuda\" if you want\n",
        "# vae_state_dict = vae_checkpoint['diffusion_state_dict']\n",
        "# vae.load_state_dict(vae_state_dict)\n",
        "optimizer = optim.Adam(vae.parameters(), lr=1e-4)\n",
        "criterion = nn.MSELoss()\n",
        "# loading pretrained vae instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qd7ioKYDO15-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd7ioKYDO15-",
        "outputId": "00753a60-c6d7-4d6b-c878-343ffc7c2bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [00:29,  3.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/2], Loss: 0.139053\n",
            "Epoch 2/2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "8it [00:26,  3.35s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/2], Loss: 0.136327\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_losses = []\n",
        "# ---- Training Loop ---- #\n",
        "def train_vae(dataloader, epochs=50):\n",
        "    vae.train()\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
        "        total_loss = 0.0\n",
        "        for i, (images, _,) in tqdm(enumerate(dataloader)):\n",
        "            images = images.to(device)  # Input maze images (shape: B x 3 x 256 x 256)\n",
        "\n",
        "            # Forward pass\n",
        "            latent_dist = vae.encode(images).latent_dist\n",
        "            latent_sample = latent_dist.sample()\n",
        "            reconstructed_images = vae.decode(latent_sample).sample\n",
        "            reconstructed_images = F.pad(reconstructed_images, (1, 1, 1, 1)) \n",
        "\n",
        "            # Loss computation\n",
        "            loss = criterion(reconstructed_images, images)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        train_losses.append(avg_loss)\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.6f}\")\n",
        "\n",
        "train_vae(dataloader, epochs=EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "Y7ye83uDSOUQ",
      "metadata": {
        "id": "Y7ye83uDSOUQ"
      },
      "outputs": [],
      "source": [
        "# torch.save({\n",
        "#     'diffusion_state_dict': vae.state_dict(),\n",
        "#     'optimizer_state_dict': optimizer.state_dict(),\n",
        "#     'train_losses': train_losses\n",
        "# }, 'diffusion_weights.pth')\n",
        "# print(\"Diffusion weights saved to diffusion_weights.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c87ee58e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save Model Weights\n",
        "if not os.path.exists(f\"../data/loss_curves_{formatted_time}/stable_diffusion_vae_models/\"):\n",
        "    os.makedirs(f\"../data/loss_curves_{formatted_time}/stable_diffusion_vae_models/\")\n",
        "torch.save({\n",
        "    'diffusion_state_dict': vae.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'train_losses': train_losses,\n",
        "}, f'../data/loss_curves_{formatted_time}/stable_diffusion_vae_models/vae_weights_multi_feat.pth')\n",
        "\n",
        "print(\"Model weights saved to vae_weights_multi_feat.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd28e29c",
      "metadata": {},
      "source": [
        "### VAE Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "SlkhuVYMSspV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "SlkhuVYMSspV",
        "outputId": "dc812d14-0cd7-4948-e9dc-6bc2fe0d00df"
      },
      "outputs": [],
      "source": [
        "# vae.eval()\n",
        "# def generate_maze_from_test(sample_idx=None):\n",
        "\n",
        "#     if sample_idx is None:\n",
        "#         sample_idx = random.randint(0, len(test_dataset) - 1)\n",
        "\n",
        "#     test_img, test_path_length, = test_dataset[sample_idx]  # Load test maze\n",
        "#     test_img = test_img.unsqueeze(0).to(device)  # Add batch dimension\n",
        "\n",
        "#     # Encode test maze image into latent space\n",
        "#     with torch.no_grad():\n",
        "#         latent_dist = vae.encode(test_img).latent_dist\n",
        "#         latent_sample = latent_dist.sample()  # Sample from the distribution\n",
        "\n",
        "#         # Decode latent back to an image\n",
        "#         generated_image = vae.decode(latent_sample).sample\n",
        "\n",
        "#     return generated_image, test_img, test_path_length\n",
        "\n",
        "# # Run test generation\n",
        "# generated, original, test_path_length = generate_maze_from_test()\n",
        "\n",
        "# # ---- Visualization ---- #\n",
        "# plt.figure(figsize=(10, 5))\n",
        "\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.imshow(generated.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# plt.title(f\"Generated Maze (Path Length: {test_path_length})\")\n",
        "# plt.axis(\"off\")\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# plt.imshow(original.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# plt.title(\"Original Test Maze\")\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4327465f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_grid_world(grid):\n",
        "    \"\"\"\n",
        "    Converts a 3-channel grid world into an RGB image for visualization.\n",
        "    - First channel: Wall (0 or 1)\n",
        "    - Second channel: Source (1 if source)\n",
        "    - Third channel: Destination (1 if destination)\n",
        "    \"\"\"\n",
        "    # print(grid[:, :, 0])\n",
        "    wall = grid[:, :, 0] < 0.5\n",
        "    source = grid[:, :, 1] >= 0.5\n",
        "    destination = grid[:, :, 2] >= 0.5\n",
        "    \n",
        "    img = np.ones((*wall.shape, 3), dtype=np.float32)  # White background\n",
        "    \n",
        "    # Set walls to black (0, 0, 0)\n",
        "    img[wall] = np.array([0, 0, 0])\n",
        "    \n",
        "    # Set destination to green (0, 1, 0)\n",
        "    img[destination] = np.array([0, 1, 0])\n",
        "\n",
        "    # Set source to blue (0, 0, 1)\n",
        "    img[source] = np.array([0, 0, 1])\n",
        "    \n",
        "    return img\n",
        "\n",
        "def visualize_sample(sample, difficulty):\n",
        "    img = visualize_grid_world(sample)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Sampled Maze — Difficulty {difficulty.item():.2f}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "ecfba3bc",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def display_reconstruction(model, dataset, device='cuda', visualize_fn=None, num_samples=5):\n",
        "    \"\"\"\n",
        "    Display discrete original vs reconstructed maze samples from the VAE using predict_discrete_structure.\n",
        "\n",
        "    Args:\n",
        "        model: Trained MazeVAE\n",
        "        dataset: Dataset returning 10x10x3 float32 tensors\n",
        "        device: Device for model + data\n",
        "        visualize_fn: Function to convert 10x10x3 integer array to RGB image\n",
        "        num_samples: Number of maze samples to display\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    fig, axes = plt.subplots(3, num_samples, figsize=(3 * num_samples, 8))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(num_samples):\n",
        "            idx = np.random.randint(len(dataset))\n",
        "            maze = dataset[idx][0].unsqueeze(0).to(torch.float32).to(device)  # shape: (1, 3, 10, 10)\n",
        "            with torch.no_grad():\n",
        "                latent_dist = vae.encode(maze).latent_dist\n",
        "                latent_sample = latent_dist.sample() \n",
        "\n",
        "                recon = vae.decode(latent_sample).sample\n",
        "                recon = F.pad(recon, pad=(1, 1, 1, 1))  # Pad (left, right, top, bottom)\n",
        "\n",
        "            # Discretize reconstruction only\n",
        "            # discrete_recon = model.predict_discrete_structure(recon).squeeze(0).cpu().numpy()\n",
        "            discrete_recon = recon.squeeze(0).permute(1, 2, 0).cpu().numpy()  # (10, 10, 3)\n",
        "            discrete_input = maze.squeeze(0).permute(1, 2, 0).cpu().numpy().astype(int)  # (10, 10, 3)\n",
        "            # discrete_recon = recon.squeeze(0).cpu().numpy()\n",
        "\n",
        "            # # Original is already discrete (from dataset)\n",
        "            # discrete_input = maze.squeeze(0).cpu().numpy().astype(int)\n",
        "\n",
        "            # Convert to RGB for display\n",
        "            orig_rgb = visualize_fn(discrete_input)\n",
        "            recon_rgb = visualize_fn(discrete_recon)\n",
        "            diff_rgb = np.abs(orig_rgb.astype(float) - recon_rgb.astype(float))\n",
        "\n",
        "            # Plot\n",
        "            axes[0, i].imshow(orig_rgb)\n",
        "            axes[0, i].axis('off')\n",
        "            axes[0, i].set_title(\"Original\")\n",
        "\n",
        "            axes[1, i].imshow(recon_rgb)\n",
        "            axes[1, i].axis('off')\n",
        "            axes[1, i].set_title(\"Reconstructed\")\n",
        "\n",
        "            axes[2, i].imshow(diff_rgb / diff_rgb.max() if diff_rgb.max() > 0 else diff_rgb)\n",
        "            axes[2, i].axis('off')\n",
        "            axes[2, i].set_title(\"Difference\")\n",
        "\n",
        "        plt.tight_layout()\n",
        "        file_name = f\"vae_generation_multi_feat_{formatted_time}\"\n",
        "        plt.savefig(os.path.join(loss_curves_folder, file_name))\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "7a626810",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 3000x800 with 30 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_reconstruction(model=vae, dataset=dataset, device=device, visualize_fn=visualize_grid_world, num_samples=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1821b8bd",
      "metadata": {},
      "source": [
        "# Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "848710e3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from diffusers import UNet2DConditionModel, DDIMScheduler\n",
        "from peft import LoraConfig\n",
        "from model import Diffusion as CustomDiffusionModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f567312",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparams\n",
        "NUM_TIMESTEPS = 1000\n",
        "GUIDANCE_SCALE = 7.5\n",
        "LATENT_SHAPE = (4, 10, 10)  # For SD 1.5\n",
        "EPOCHS = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "62efeb99",
      "metadata": {},
      "outputs": [],
      "source": [
        "unet = UNet2DConditionModel.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"unet\").to(device)\n",
        "unet.requires_grad_(False)\n",
        "lora_config = LoraConfig(\n",
        "        r=4,\n",
        "        lora_alpha=16,\n",
        "        init_lora_weights=\"gaussian\",\n",
        "        target_modules=[\"to_k\", \"to_q\", \"to_v\", \"to_out.0\"],\n",
        "    )\n",
        "unet.add_adapter(lora_config)\n",
        "lora_layers = filter(lambda p: p.requires_grad, unet.parameters())\n",
        "optimizer = torch.optim.Adam(\n",
        "    lora_layers, lr=1e-5, betas=(0.9, 0.999), weight_decay=1e-2, eps=1e-08)\n",
        "scheduler = DDIMScheduler.from_pretrained(\"runwayml/stable-diffusion-v1-5\", subfolder=\"scheduler\")\n",
        "# custom_diffusion_model = CustomDiffusionModel(input_size=2).to(device)\n",
        "scheduler.set_timesteps(NUM_TIMESTEPS)\n",
        "vae.eval()\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", subfolder=\"tokenizer\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\", subfolder=\"text_encoder\").to(device)\n",
        "# optimizer = torch.optim.Adam(list(unet.parameters()), lr=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aedc139",
      "metadata": {},
      "source": [
        "### Stable Diffusion Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "32c19b54",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training epoch [1/1]: 100%|██████████| 8/8 [04:33<00:00, 34.16s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Epoch 1] Loss: 1.727044\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAHWCAYAAACIZjNQAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPM1JREFUeJzt3QeYFdUdN+CzdFFBAWmKgB1F0VixxEZENETEXgFbVDQqsUbEHhITTewtKhoxxgZRoxgkCjHBICoaG4qiIEVs9KZwv+ec77v324UFFtydZXff93nG3Zk5d+7M3XmW/XnO+U9RLpfLBQAAACpUrYo9PAAAAJHwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AVAhevdu3do167dGr32qquuCkVFReV+TmQn/zP86quvKvtUACqV8AVQg8U/iMuyvPzyy6Gmhsb11lsvVBXPPPNM6N69e2jRokWoV69eaNKkSfjxj38cbrzxxjB79uzKPj2AGq9OZZ8AAJXnz3/+c4n1hx56KAwfPny57R06dPhB73PvvfeGpUuXrtFr+/fvHy699NIf9P7VXfxsTz311DBo0KCw/fbbh7PPPju0adMmzJkzJ4wePTp9hs8991wYMWJEZZ8qQI0mfAHUYCeeeGKJ9VdffTWFr2W3L2v+/PmhYcOGZX6funXrrvE51qlTJy2s2A033JCC1wUXXJB6uYoP0zzvvPPCtGnTUrBeVYBbvHhxaNCgQQZnDFAzGXYIwErtt99+oWPHjuH1119PQ9hi6PrVr36V9v3tb38Lhx56aGjdunWoX79+2HzzzcO1114blixZstI5X59++mkKCL///e/DPffck14XX7/rrruG1157bZVzvuL6OeecE4YOHZrOLb52u+22C8OGDVvu/OOQyV122SWFivg+d999d7nPI3v88cfDzjvvHNZZZ53QrFmzFF6nTJlSos306dNDnz59wiabbJLOt1WrVuGwww5Ln0Xe2LFjQ9euXdMx4rHat28fTjnllFUG4d/+9rfp+n/3u9+Vel3xvS655JJSP8PBgwen18Zzyn9+8eey5557hqZNm6bziNf2xBNPLHfc4sfYeuut02cc244aNarUc505c2a6FzbYYIPQuHHj9HnE8weoKfyvRABW6euvvw7dunULxx57bAoWcU5RFHtb4pyofv36pa///Oc/w4ABA9L8ohgEVuWRRx5JQ+N+/vOfpz/kYw9Oz549wyeffLLK3rJXXnklPPXUU2mI3frrrx9uueWWcMQRR4RJkyal0BC9+eab4eCDD07h4+qrr06h8JprrgkbbbRROX0y//cziCEiBseBAweGL774Itx8883h3//+d3r/GDSieG7vvvtuOPfcc1MQnTFjRupljOebXz/ooIPSucVhlvF1MZjFa1zV5xBDzYUXXhhq1669Wucef16PPfZYClAx8OUDcjz/n/3sZ+GEE05IvWGPPvpoOOqoo8Kzzz6bwnZxI0eODH/961/DL37xixTg7rjjjvSZjxkzJgXj4o4++ugUKOPn9MYbb4Q//elPoXnz5ik8AtQIOQD4f/r27Ztb9p+GfffdN2276667lms/f/785bb9/Oc/zzVs2DC3cOHCwrZevXrl2rZtW1ifOHFiOmbTpk1z33zzTWH73/72t7T9mWeeKWy78sorlzunuF6vXr3chAkTCtveeuuttP3WW28tbOvevXs6lylTphS2ffTRR7k6deosd8zSxPNed911V7h/8eLFuebNm+c6duyYW7BgQWH7s88+m44/YMCAtP7tt9+m9d/97ncrPNaQIUNSm9deey23Om6++eb0uqFDh5bY/v333+e+/PLLEsvSpUsL++NratWqlXv33XdX+XON1xmv8YADDiixPR4jLmPHji1s++yzz3INGjTIHX744cv9DE855ZQSr49t4j0AUFMYdgjAKsUejdi7s6w4JC0v9mDFUuL77LNPGkr2wQcfrPK4xxxzTNhwww0L6/G1Uez5WpUuXbqkYYR5O+ywQ2jUqFHhtbGX68UXXww9evRIwyLztthii9SLVx7iMMHYYxV734rPlYq9Q9tss034+9//XvicYvXBOATy22+/LfVY+R6y2Lv03Xfflfkc8lUMl63K+L///S/1ohVfYg9mcfvuu2/YdtttV/pzjec7a9as9LOJvVXL6ty5cxpqmLfpppum4ZQvvPDCcsNPzzzzzBLr8ZjxnFRiBGoK4QuAVdp4441TeFhWHEZ3+OGHp/k7MfjEP/DzxTriH+yrEv9QLy4fxFYUUFb22vzr86+NoWjBggUpbC2rtG1r4rPPPktf43ynZcXwld8fw2scWvf888+nIZtx7lwcYhnngRUPQnFoYhweGYcAxgDzwAMPhEWLFq30HOKQy2ju3LnLXWMc1hiXk046qdTXxiGApYkBcI899kiBMparjz/XO++8s9Sf6ZZbbrnctq222ioF8C+//LLcft4A1YHwBcAqFe8JyYvzjGJgeOutt9I8qviMqfiHfn7+TllKy69ojtL/HdFWca+tDOeff3748MMP03ynGGquuOKKVMI/zguL4py3WNQiloaPc7BiwY5YbCP2Ki0brJYNedE777xTYnvsCYu9g3HZbLPNyvxz/de//pXme8VzjPO3Yon6+HM9/vjjf/BnW9V+ZgDlTfgCYI3EIXRxyFgsOBHLmf/0pz9Nf+gXH0ZYmWIhhxggJkyYsNy+0ratibZt26av48ePX25f3JbfnxeHSf7yl78M//jHP1JYisUsYmn44mKP0/XXX5+GNMYqgrF3MRa8WJE4dC/2PMY2a/osteKefPLJ9LnFYYMx/MUhmvHnuiIfffTRcttiyIxVMcuzsAlAdSB8AfCDejGK91rEMBF7S9aW84uhIZajnzp1aongFYf/lYdYwj6GvLvuuqvE8MB4/Pfff79QGTAOwVu4cOFyQSwOGcy/Lg69W7YHaMcdd0xfVzb0MIaciy++OIW5WCWxtF6k1elZip9b7IUrPl8rVl2Mn2NpYk9d8blgkydPTo8giJUbV7f6IkB1p9Q8AGskPgcq9nL16tUrlRmPf7D/+c9/XquGkMXnecVepr322iucddZZKVDcdtttqQT6uHHjynSMWPziuuuuW257nAsVC23EYZaxGEkcgnnccccVSs3Hsu3xocf5nqADDzwwlVqPBS7iQ6OHDBmS2sby/dGDDz6YgmucQxeDWSxgcu+996a5dIcccshKzzGGrhj2Ynn/eL1x7lh8nlgMdDEYxeeQ5XsCVyUGxptuuimVi49DDePcudtvvz3NIXv77beXax8/y/hssuKl5qM4dw2AkoQvANZIfJZWLMwQh9H1798/BbFYbCOGjPjH+NogzpeKvVDxGVhxjlWbNm3S/LQYVMpSjTHfmxdfu6wYkGL4ig8Njr1Pv/nNb9KDjNddd90UoGIoy1cwjO8bg9mIESNSQI3hK87Vis/YikEpiuEtPhsrDh+MoSwOJdxtt93S0MMVFcbIq1WrVjpuPFYMbLfeemsKXnHeVwxHcRjj6aefvlxFxNIccMAB4b777kvXE+epxfeO1xJ7v0oLX/G8Y8XDGLbiM8tiuIxDUWP1SQBKKor15pfZBgDVWiw/H+dSlTZfibKLvZ19+/ZNvYkArJo5XwBUa7HcfHExcMUKfvvtt1+lnRMANZNhhwBUa7HMehwaGL/G527F51XFZ5bFIhUAkCXhC4BqLRaO+Mtf/pIeaBwLQsT5Sb/+9a9LfTgwAFQkc74AAAAyYM4XAABABoQvAACADJjztYaWLl0apk6dGtZff/1UahcAAKiZcrlcmDNnTmjdunV69uKKCF9rKAav+NBMAACAaPLkyWGTTTYJKyJ8raHY45X/gBs1alTZpwMAAFSS2bNnp46ZfEZYEeFrDeWHGsbgJXwBAABFq5iOpOAGAABABoQvAACADAhfAAAAGTDnCwAAKqj8+Pfffx+WLFlS2afCD1S7du1Qp06dH/yIKeELAADK2eLFi8O0adPC/PnzK/tUKCcNGzYMrVq1CvXq1VvjYwhfAABQjpYuXRomTpyYekviQ3fjH+s/tMeEyu3BjGH6yy+/TD/XLbfccqUPUl4Z4QsAAMpR/EM9BrD43KfYW0LVt84664S6deuGzz77LP18GzRosEbHUXADAAAqwJr2jlB9f57uCAAAgAwIXwAAABkQvgAAYC20ZGkujP746/C3cVPS17he1bRr1y788Y9/rOzTWGsouAEAAGuZYe9MC1c/816YNmthYVurxg3Cld23DQd3bFXu77eqaoxXXnlluOqqq1b7uK+99lpYd911f8CZhbDffvuFHXfcsVqEOOELAADWsuB11sNvhGX7uabPWpi233nij8o9gMVnkuX99a9/DQMGDAjjx48vbFtvvfVKlF6PD46ODx1elY022qhcz7OqM+wQAAAqUAwr8xd/X6ZlzsLvwpVPv7tc8ErH+X9fr3r6vdSuLMeL710WLVu2LCyNGzdOPWH59Q8++CCsv/764fnnnw8777xzqF+/fnjllVfCxx9/HA477LDQokWLFM523XXX8OKLL6502GFRUVH405/+FA4//PBUhj8+M+vpp5/+QZ/vk08+Gbbbbrt0XvH9brzxxhL777jjjvQ+sTx8PNcjjzyysO+JJ54I22+/fSol37Rp09ClS5cwb968UFH0fAEAQAVa8N2SsO2AF8rlWDFKTZ+9MGx/1T/K1P69a7qGhvXK50/+Sy+9NPz+978Pm222Wdhwww3D5MmTwyGHHBKuv/76FHweeuih0L1799Rjtummm67wOFdffXW44YYbwu9+97tw6623hhNOOCE9P6tJkyarfU6vv/56OProo9OQyGOOOSb85z//CWeffXYKUr179w5jx44Nv/jFL8Kf//znsOeee4Zvvvkm/Otf/yr09h133HHpXGIYnDNnTtpX1sC6JoQvAABgla655prwk5/8pLAew1KnTp0K69dee20YMmRI6sk655xzVnic3r17p9AT/frXvw633HJLGDNmTDj44INX+5xuuummcOCBB4YrrrgirW+11VbhvffeS8Euvs+kSZPSnLOf/vSnqfeubdu2YaeddiqEr++//z707NkzbY9iL1hFEr4AAKACrVO3duqBKosxE78JvR94bZXtBvXZNezWvkmZ3ru87LLLLiXW586dm3qc/v73vxeCzIIFC1LgWZkddtih8H0MRo0aNQozZsxYo3N6//3309DH4vbaa6801DHOS4thMQar2FsXw11c8kMeY3CMwS0Grq5du4aDDjooDUmMvXoVxZwvAACoQHGeUxz6V5Zlny03SlUNV1R7MG6P+2O7shxvVVUMV8eyVQsvvPDC1NMVe6/icL1x48alILN48eKVHqdu3bolr6moKCxdujRUhNjb9cYbb4S//OUvoVWrVqmQSAxdM2fODLVr1w7Dhw9Pc9m23XbbNARy6623DhMnTgwVRfgCAIC1RO1aRamcfLRsbMqvx/2xXWX797//nYb2xZ6kGLpicY5PP/0003Po0KFDOo9lzysOP4zhKopVGWMhjTi36+23307n+M9//rMQ/GJPWZyH9uabb4Z69eqlQFlRDDsEAIC1SCwjH8vJL/ucr5YV+JyvNRErCD711FOpyEYMMXHeVUX1YH355ZepZ6242JP1y1/+MlVZjPPNYsGN0aNHh9tuuy1VOIyeffbZ8Mknn4Qf//jHaTjhc889l84x9nD997//DSNGjEjDDZs3b57W4/vEQFdRhC8AAFjLxID1k21bpjlgM+YsDM3Xb5DmeK0NPV7Fi12ccsopqYpgs2bNwiWXXBJmz55dIe/1yCOPpKW4GLj69+8fHnvssTScMK7HQBYLg8QeuWiDDTZIATHOTVu4cGEKjHEIYixNH+eLjRo1Ks0Pi+cd54bFMvXdunULFaUoV5G1FKux+AOKz0CYNWtWmiQIAABR/CM/zhtq3759erYU1f/nOruM2cCcLwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAgAqgrl31kiuHn6fwBQAA5ahu3brp6/z58yv7VChH+Z9n/ue7JjznCwAAylHt2rXT86VmzJiR1hs2bJgeQkzV7fGKwSv+POPPNf5815TwBQAA5axly5bpaz6AUfXF4JX/ua4p4QsAAMpZ7Olq1apVaN68efjuu+8q+3T4geJQwx/S45UnfAEAQAWJf7CXxx/tVA8KbgAAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEB1D1+jRo0K3bt3D61bt07lOIcOHbrK1wwePDh06tQpPawulu885ZRTwtdff12izeOPPx622Wab0KBBg7D99tuH5557brkHpQ0YMCC9fp111gldunQJH330UblfHwAAwFoRvubNm5eC1O23316m9v/+97/DySefHE499dTw7rvvppA1ZsyYcPrppxfa/Oc//wnHHXdcavPmm2+GHj16pOWdd94ptLnhhhvCLbfcEu66667w3//+N6y77rqha9euYeHChRVynQAAAEW52A20Fog9X0OGDElBaUV+//vfhzvvvDN8/PHHhW233npr+O1vfxs+//zztH7MMcekUPfss88W2uyxxx5hxx13TGErXm7safvlL38ZLrzwwrR/1qxZoUWLFmHQoEHh2GOPLdP5zp49OzRu3Di9tlGjRj/gygEAgKqsrNmgSs356ty5c5g8eXIaRhhD1BdffBGeeOKJcMghhxTajB49Og0jLC72asXt0cSJE8P06dNLtIkf1O67715oU5pFixalD7X4AgAAUFZVKnzttddeac5X7N2qV69eaNmyZQpOxYctxmAVe7GKi+txe35/ftuK2pRm4MCB6b3yS5s2bcr56gAAgOqsSoWv9957L5x33nmpWMbrr78ehg0bFj799NNw5plnVvh7X3bZZakbMb/EHjgAAICyqhOqkNj7FHu/LrroorS+ww47pGIZ++yzT7juuutS9cLYGxaHIxYX1+P2KP81bovti7eJ88JWpH79+mkBAACo9j1f8+fPD7VqlTzl2rVrp6/5uiFxXtiIESNKtBk+fHjaHrVv3z4FsOJt4vytWPUw3wYAAKBa9XzNnTs3TJgwobAei2GMGzcuNGnSJGy66aZpqN+UKVPCQw89lPbHZ4LFsvKx4mEsojFt2rRw/vnnh9122y1VMIzisMR999033HjjjeHQQw8Njz76aBg7dmy45557ClUV42tiT9mWW26ZwtgVV1yRXr+ySosAAABVNnzFULT//vsX1vv165e+9urVK5V9j+Fq0qRJhf29e/cOc+bMCbfddlsqFb/BBhuEAw44IJWaz9tzzz3DI488Evr37x9+9atfpYAVH97csWPHQpuLL744laM/44wzwsyZM8Pee++d5o/FhzIDAABU6+d8VTWe8wUAAFTb53wBAABUVcIXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAAAZEL4AAAAyIHwBAABkQPgCAADIgPAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAFDdw9eoUaNC9+7dQ+vWrUNRUVEYOnToStv37t07tVt22W677Qpt2rVrV2qbvn37Ftrst99+y+0/88wzK/RaAQCAmq1Sw9e8efNCp06dwu23316m9jfffHOYNm1aYZk8eXJo0qRJOOqoowptXnvttRJthg8fnrYXbxOdfvrpJdrdcMMN5Xx1AAAA/1+dUIm6deuWlrJq3LhxWvJiT9m3334b+vTpU9i20UYblXjNb37zm7D55puHfffdt8T2hg0bhpYtW/6g8wcAAKgRc77uu+++0KVLl9C2bdtS9y9evDg8/PDD4ZRTTklDC4sbPHhwaNasWejYsWO47LLLwvz581f6XosWLQqzZ88usQAAAFSJnq8fYurUqeH5558PjzzyyArbxJ6xmTNnprlixR1//PEpsMW5Zm+//Xa45JJLwvjx48NTTz21wmMNHDgwXH311eV6DQAAQM1RlMvlcmEtEHumhgwZEnr06FGm9jEM3XjjjSmE1atXr9Q2Xbt2TfueeeaZlR7rn//8ZzjwwAPDhAkT0hDFFfV8xSUv9ny1adMmzJo1KzRq1KhM5wwAAFQ/MRvE6VGrygZVsucr5sX7778/nHTSSSsMXp999ll48cUXV9qblbf77runrysLX/Xr108LAABAjZnzNXLkyBSUTj311BW2eeCBB0Lz5s3DoYceusrjjRs3Ln1t1apVuZ4nAADAWtHzNXfu3BSi8iZOnJiCUCwfv+mmm6ZCGFOmTAkPPfTQcoU2Ym9VLJZRmqVLl6bw1atXr1CnTslL/Pjjj9M8sUMOOSQ0bdo0zfm64IILwo9//OOwww47VNCVAgAANV2lhq+xY8eG/fffv7Der1+/9DWGpkGDBqXnb02aNKnEa+I4yieffDI982tF4nDD+LpY5XBZcZhi3P/HP/4xPWcszts64ogjQv/+/cv12gAAANbKghvVdVIdAABQvZU1G1TJOV8AAABVjfAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAAAZEL4AAAAyIHwBAABkQPgCAADIgPAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAFT38DVq1KjQvXv30Lp161BUVBSGDh260va9e/dO7ZZdtttuu0Kbq666arn922yzTYnjLFy4MPTt2zc0bdo0rLfeeuGII44IX3zxRYVdJwAAQKWGr3nz5oVOnTqF22+/vUztb7755jBt2rTCMnny5NCkSZNw1FFHlWgXw1jxdq+88kqJ/RdccEF45plnwuOPPx5GjhwZpk6dGnr27Fmu1wYAAFBcnVCJunXrlpayaty4cVryYk/Zt99+G/r06VOiXZ06dULLli1LPcasWbPCfffdFx555JFwwAEHpG0PPPBA6NChQ3j11VfDHnvsscbXAwAAUC3nfMUQ1aVLl9C2bdsS2z/66KM0lHGzzTYLJ5xwQpg0aVJh3+uvvx6+++679Lq8OCxx0003DaNHj17hey1atCjMnj27xAIAAFDtw1ccKvj888+H0047rcT23XffPQwaNCgMGzYs3HnnnWHixIlhn332CXPmzEn7p0+fHurVqxc22GCDEq9r0aJF2rciAwcOLPS8xaVNmzYVdGUAAEB1VGXD14MPPpgCVI8ePUpsj8MY4xywHXbYIXTt2jU899xzYebMmeGxxx77Qe932WWXpSGL+SXONwMAAKgSc77WVC6XC/fff3846aSTUi/WysSAttVWW4UJEyak9TgXbPHixSmQFe/9itUOVzRPLKpfv35aAAAAakzPV6xQGMPUqaeeusq2c+fODR9//HFo1apVWt95551D3bp1w4gRIwptxo8fn+aFde7cuULPGwAAqLkqtecrBqN8j1QU52eNGzculY+PBTDiUL8pU6aEhx56aLlCG3FuV8eOHZc75oUXXpieHRaLcMR5YVdeeWWoXbt2OO6449L+OF8rhrZ+/fql92nUqFE499xzU/BS6RAAAKiW4Wvs2LFh//33L6zHQBT16tUrFc2Iz+gqXqkwivOtnnzyyfTMr9J8/vnnKWh9/fXXYaONNgp77713KiEfv8/7wx/+EGrVqpUerhyrGMa5YXfccUeFXScAAEBRLk6gYrXFUvOxFy2Gwdh7BgAA1Eyzy5gNquScLwAAgKpG+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAAAZEL4AAAAyIHwBAABkQPgCAADIgPAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAAGBtDV+TJ08On3/+eWF9zJgx4fzzzw/33HNPeZ4bAABAzQ5fxx9/fHjppZfS99OnTw8/+clPUgC7/PLLwzXXXFPe5wgAAFAzw9c777wTdtttt/T9Y489Fjp27Bj+85//hMGDB4dBgwaV9zkCAADUzPD13Xffhfr166fvX3zxxfCzn/0sfb/NNtuEadOmle8ZAgAA1NTwtd1224W77ror/Otf/wrDhw8PBx98cNo+derU0LRp0/I+RwAAgJoZvn7729+Gu+++O+y3337huOOOC506dUrbn3766cJwRAAAAP6/olwulwtrYMmSJWH27Nlhww03LGz79NNPQ8OGDUPz5s1DdRevvXHjxmHWrFmhUaNGlX06AGRsydJcGDPxmzBjzsLQfP0GYbf2TULtWkWVfVoArMXZoM6aHHzBggUhZrZ88Prss8/CkCFDQocOHULXrl3X/KwBoAoY9s60cPUz74VpsxYWtrVq3CBc2X3bcHDHVpV6bgBUs2GHhx12WHjooYfS9zNnzgy77757uPHGG0OPHj3CnXfeWd7nCABrVfA66+E3SgSvaPqshWl73A8A5Ra+3njjjbDPPvuk75944onQokWL1PsVA9ktt9yyJocEgCox1DD2eJU2Xj+/Le6P7QCgXMLX/Pnzw/rrr5++/8c//hF69uwZatWqFfbYY48UwgCgOopzvJbt8SouRq64P7YDgHIJX1tssUUYOnRomDx5cnjhhRfCQQcdlLbPmDFjtYpPjBo1KnTv3j20bt06FBUVpWOuTO/evVO7ZZdY+j5v4MCBYdddd03hMBb+iEMhx48fX+I4sUrjssc488wzV/tzAKBmicU1yrMdADXLGoWvAQMGhAsvvDC0a9culZbv3LlzoRdsp512KvNx5s2bl8rU33777WVqf/PNN6eHOOeXGP6aNGkSjjrqqEKbkSNHhr59+4ZXX301PYMsPhA6hsP4XsWdfvrpJY51ww03lPm8AaiZYlXD8mwHQM2yRtUOjzzyyLD33nun0JJ/xld04IEHhsMPP7zMx+nWrVtayiqWb4xLXuwp+/bbb0OfPn0K24YNG1biNYMGDUo9YK+//nr48Y9/XNgeS+K3bNmyzO8NALGcfKxqGItrlDarKxaab9n4/5adB4By6fmKYnCJvVxTp04Nn3/+edoWe8G22WabkJX77rsvdOnSJbRt23aFbWKt/Sj2kBU3ePDg0KxZs9CxY8dw2WWXpXlsK7No0aJUv7/4AkDNEp/jFcvJR8s+0Su/Hvd73hcA5Ra+li5dGq655prUCxWDT1w22GCDcO2116Z9WYih7/nnnw+nnXbaSs/z/PPPD3vttVcKWXnHH398ePjhh8NLL72Ugtef//zncOKJJ670/eJcsnzPW1zatGlTrtcDQNUQn+N154k/Sj1cxcX1uN1zvgAo12GHl19+eep1+s1vfpOCTfTKK6+Eq666KixcuDBcf/31oaI9+OCDKfDFghorEud+vfPOO+ncijvjjDMK32+//fahVatWacjkxx9/HDbffPNSjxVDWr9+/QrrsedLAAOomWLA+sm2LVNVw1hcI87xikMN9XgBUO7hKwafP/3pT+FnP/tZYdsOO+wQNt5443D22WdXePjK5XLh/vvvDyeddFKoV69eqW3OOeec8Oyzz6aKiptssslKjxcfEh1NmDBhheGrfv36aQGAKAatzps3rezTAKC6h69vvvmm1LldcVvcV9FiRcMYlE499dRSg9m5554bhgwZEl5++eXQvn37VR5v3Lhx6WvsAQMAAFhr5nzFCoe33XbbctvjttgDVlZz585NwScffiZOnJi+nzRpUmGo38knn7zc6+KQx9hbVXweV/GhhnE+1yOPPJKe9TV9+vS0LFiwIO2PQwvj3LRY/fDTTz8NTz/9dHqPWAlxdc4dAABgdRTlYlfRGvQ8HXrooWHTTTctPONr9OjR6blbzz33XNhnn33KdJzYM7X//vsvt71Xr16pRHx8qHIMSLFd8eqFsYcqPvMrPqtruQsqKn28/QMPPJCOF88xFteIc8His7/ivK1YHr9///6r9YDoOOcrFt6I57M6rwMAAKqXsmaDNQpf+WqD8eHIH3zwQVrv0KFDKmRx3XXXhXvuuSdUd8IXAACQSfgqzVtvvRV+9KMfhSVLloTqTvgCAABWJxus8UOWAQAAKDvhCwAAIAPCFwAAwNr2nK+ePXuudP/MmTN/6PkAAABUS6sVvuIkslXtL+25XAAAADXdaoWv+KwsAAAAVp85XwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAAAZEL4AAAAyIHwBAABkQPgCAADIgPAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAADVPXyNGjUqdO/ePbRu3ToUFRWFoUOHrrR97969U7tll+22265Eu9tvvz20a9cuNGjQIOy+++5hzJgxJfYvXLgw9O3bNzRt2jSst9564YgjjghffPFFhVwjAABApYevefPmhU6dOqWwVBY333xzmDZtWmGZPHlyaNKkSTjqqKMKbf7617+Gfv36hSuvvDK88cYb6fhdu3YNM2bMKLS54IILwjPPPBMef/zxMHLkyDB16tTQs2fPCrlGAACAqCiXy+XWho8i9mANGTIk9OjRo8yviT1lMTRNnDgxtG3bNm2LPV277rpruO2229L60qVLQ5s2bcK5554bLr300jBr1qyw0UYbhUceeSQceeSRqc0HH3wQOnToEEaPHh322GOPMr337NmzQ+PGjdPxGjVqtEbXDAAAVH1lzQZVes7XfffdF7p06VIIXosXLw6vv/562pZXq1attB6DVRT3f/fddyXabLPNNmHTTTcttCnNokWL0odafAEAACirKhu+4lDB559/Ppx22mmFbV999VVYsmRJaNGiRYm2cX369Onp+/i1Xr16YYMNNlhhm9IMHDgwpdn8EnvTAAAAqn34evDBB1OAWp1hij/EZZddlroR80ucbwYAAFBWdUIVFKep3X///eGkk05KvVh5zZo1C7Vr116ucmFcb9myZfo+fo3DE2fOnFmi96t4m9LUr18/LQAAADWm5ytWKJwwYUI49dRTS2yPQWznnXcOI0aMKGyLBTfieufOndN63F+3bt0SbcaPHx8mTZpUaAMAAFCter7mzp2bQlRerFo4bty4VD4+FsCIQ/2mTJkSHnrooeUKbcSqhh07dlzumLHMfK9evcIuu+wSdtttt/DHP/4xlbTv06dP2h/na8XQFtvF94nVSGIlxBi8ylrpEAAAoEqFr7Fjx4b999+/sB4DURTD06BBg9KzvGKPVHFxvtWTTz6ZnvlVmmOOOSZ8+eWXYcCAAamAxo477hiGDRtWogjHH/7wh1QFMT5cOVYxjM8Bu+OOOyrsOgEAANaa53xVNZ7zBQAA1JjnfAEAAFQVwhcAAEAGhC8AAIAMCF8AAAAZEL4AAAAyIHwBAABkQPgCAADIgPAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAAAZEL4AAAAyIHwBAABkQPgCAADIgPAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAUN3D16hRo0L37t1D69atQ1FRURg6dOgqX7No0aJw+eWXh7Zt24b69euHdu3ahfvvv7+wf7/99kvHWnY59NBDC2169+693P6DDz64wq4TAACgTmW++bx580KnTp3CKaecEnr27Fmm1xx99NHhiy++CPfdd1/YYostwrRp08LSpUsL+5966qmwePHiwvrXX3+d3uOoo44qcZwYth544IHCegxyAAAA1TJ8devWLS1lNWzYsDBy5MjwySefhCZNmqRtseeruPz2vEcffTQ0bNhwufAVw1bLli1/0PkDAABUyzlfTz/9dNhll13CDTfcEDbeeOOw1VZbhQsvvDAsWLBgha+JPWTHHntsWHfddUtsf/nll0Pz5s3D1ltvHc4666zUQ7aq4Y6zZ88usQAAAFSJnq/VFXu8XnnlldCgQYMwZMiQ8NVXX4Wzzz47BafiQwjzxowZE955550UwJYdchiHObZv3z58/PHH4Ve/+lXqgRs9enSoXbt2qe89cODAcPXVV1fYtQEAANVbUS6Xy4W1QCx6EQNVjx49VtjmoIMOCv/617/C9OnTQ+PGjQtzvI488sg0f2ydddYp0f7nP/95ClRvv/32KkPd5ptvHl588cVw4IEHrrDnKy55seerTZs2YdasWaFRo0arebUAAEB1EbNBzCerygZVathhq1at0nDDfPCKOnToEGJ+/Pzzz0u0jWEszvc69dRTV3nczTbbLDRr1ixMmDBhhW3iHLH4QRZfAAAAyqpKha+99torTJ06NcydO7ew7cMPPwy1atUKm2yySYm2jz/+eOqpOvHEE1d53Bjc4tDFGO4AAACqXfiKIWrcuHFpiSZOnJi+nzRpUlq/7LLLwsknn1xof/zxx4emTZuGPn36hPfeey89J+yiiy5KpeqXHXIY53nFIYyx/bLvGV/z6quvhk8//TSMGDEiHHbYYalsfdeuXTO5bgAAoOap1PA1duzYsNNOO6Ul6tevX/p+wIABaT0+wysfxKL11lsvDB8+PMycOTNVPTzhhBPSQ5pvueWWEscdP358KsxR2pDDWFAjzgH72c9+lqolxjY777xzmkvmWV8AAEC1L7hRXSfVAQAA1Vu1LLgBAABQVQlfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAAAZEL4AAAAyIHwBAABkQPgCAADIgPAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAAKC6h69Ro0aF7t27h9atW4eioqIwdOjQVb5m0aJF4fLLLw9t27YN9evXD+3atQv3339/Yf+gQYPSsYovDRo0KHGMXC4XBgwYEFq1ahXWWWed0KVLl/DRRx9VyDUCAABEdSrzY5g3b17o1KlTOOWUU0LPnj3L9Jqjjz46fPHFF+G+++4LW2yxRZg2bVpYunRpiTaNGjUK48ePL6zHAFbcDTfcEG655Zbw4IMPhvbt24crrrgidO3aNbz33nvLBTUAAIAqH766deuWlrIaNmxYGDlyZPjkk09CkyZN0rbY87WsGLZatmxZ6jFir9cf//jH0L9//3DYYYelbQ899FBo0aJF6nk79thj1/h6AAAAqsWcr6effjrssssuqedq4403DltttVW48MILw4IFC0q0mzt3bhqW2KZNmxSw3n333cK+iRMnhunTp6ehhnmNGzcOu+++exg9evRKhzvOnj27xAIAAFAtw1fs8XrllVfCO++8E4YMGZJ6sJ544olw9tlnF9psvfXWaQ7Y3/72t/Dwww+nIYl77rln+Pzzz9P+GLyi2NNVXFzP7yvNwIEDU0jLLzHYAQAAVMvwFYNUHFI4ePDgsNtuu4VDDjkk3HTTTWnuVr73q3PnzuHkk08OO+64Y9h3333DU089FTbaaKNw9913/6D3vuyyy8KsWbMKy+TJk8vpqgAAgJqgSoWvWJ0wDjeMPU95HTp0SPO48j1by6pbt27YaaedwoQJE9J6fi5YLNpRXFxf0TyxKFZWjIU8ii8AAADVMnzttddeYerUqWlOV96HH34YatWqFTbZZJNSX7NkyZLwv//9LwW3KFY3jCFrxIgRhTZx/tZ///vf1GsGAABQ7cJXDFHjxo1LS74YRvx+0qRJhaF+cQhh3vHHHx+aNm0a+vTpk8rCx+eEXXTRRalUfXxeV3TNNdeEf/zjH2l+2BtvvBFOPPHE8Nlnn4XTTjst7Y/DFs8///xw3XXXpQIeMZjF94jPGuvRo0elfA4AAED1V6ml5seOHRv233//wnq/fv3S1169eqWHJcdneOWDWLTeeuuF4cOHh3PPPTdVPYxBLD73KwapvG+//TacfvrpqXjGhhtuGHbeeefwn//8J2y77baFNhdffHF6xtgZZ5wRZs6cGfbee+9Uxt4zvgAAgIpSlIsTplhtcahinHsWi2+Y/wUAADXX7DJmgyo15wsAAKCqEr4AAAAyIHwBAABkQPgCAADIgPAFAACQAeELAAAgA8IXAABABoQvAACADAhfAAAAGRC+AAAAMiB8AQAAZED4AgAAyIDwBQAAkAHhCwAAIAPCFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAAAZEL4AAAAyIHwBAABkQPgCAADIgPAFAACQgTpZvEl1lMvl0tfZs2dX9qkAAACVKJ8J8hlhRYSvNTRnzpz0tU2bNpV9KgAAwFqSERo3brzC/UW5VcUzSrV06dIwderUsP7664eioqLKPh1W8n8hYkCePHlyaNSoUWWfDms59wuryz3D6nLPsLrcM1VDjFQxeLVu3TrUqrXimV16vtZQ/FA32WSTyj4Nyij+svILi7Jyv7C63DOsLvcMq8s9s/ZbWY9XnoIbAAAAGRC+AAAAMiB8Ua3Vr18/XHnllekrrIr7hdXlnmF1uWdYXe6Z6kXBDQAAgAzo+QIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC+qlNtvvz20a9cuNGjQIOy+++5hzJgxK2z73XffhWuuuSZsvvnmqX2nTp3CsGHDlms3ZcqUcOKJJ4amTZuGddZZJ2y//fZh7NixFXwlVNV7ZsmSJeGKK64I7du3T/dLbHvttdemJ9tT9Y0aNSp07949tG7dOhQVFYWhQ4eu8jUvv/xy+NGPfpQqkW2xxRZh0KBBP+g+pGbfLwMHDgy77rprWH/99UPz5s1Djx49wvjx4yvwKqgOv2PyfvOb36Tjnn/++eV85pQX4Ysq469//Wvo169fKrf6xhtvpD+Mu3btGmbMmFFq+/79+4e777473HrrreG9994LZ555Zjj88MPDm2++WWjz7bffhr322ivUrVs3PP/886ndjTfeGDbccMMMr4yqdM/89re/DXfeeWe47bbbwvvvv5/Wb7jhhvQaqr558+al+ySGpbKYOHFiOPTQQ8P+++8fxo0bl/7gOe2008ILL7ywxvchNft+GTlyZOjbt2949dVXw/Dhw9P/FDrooIPSe1H1VcQ9k/faa6+lf8N22GGHCjhzyk0sNQ9VwW677Zbr27dvYX3JkiW51q1b5wYOHFhq+1atWuVuu+22Ett69uyZO+GEEwrrl1xySW7vvfeuwLOmut0zhx56aO6UU05ZaRuqh/hP5JAhQ1ba5uKLL85tt912JbYdc8wxua5du67xfUjNvl+WNWPGjHTskSNHltu5Uv3umTlz5uS23HLL3PDhw3P77rtv7rzzzquQc+aH0/NFlbB48eLw+uuvhy5duhS21apVK62PHj261NcsWrQoDfEpLg4Te+WVVwrrTz/9dNhll13CUUcdlYZ37LTTTuHee++twCuhqt8ze+65ZxgxYkT48MMP0/pbb72V9nfr1q3CroW1V7yXit9jUezVyt9ja3IfUnPvl9LMmjUrfW3SpEmFnx9V956JvaWxh2zZtqx9hC+qhK+++irNtWnRokWJ7XF9+vTppb4m/nK66aabwkcffRSWLl2ahm889dRTYdq0aYU2n3zySRpCtuWWW6Yu/LPOOiv84he/CA8++GCFXxNV85659NJLw7HHHhu22WabNFw1BvY4DOSEE06o8Gti7RPvpdLusdmzZ4cFCxas0X1Izb1flhV/D8XfL3F4fMeOHTM8U6rSPfPoo4+mIc1xviBrP+GLauvmm29OoSr+kVyvXr1wzjnnhD59+qT/61z8H7Y4ifXXv/51+iP6jDPOCKeffnq46667KvXcWXvvmcceeywMHjw4PPLII+kfuxjUf//73wvsQLmLvRnvvPNO+uMaSjN58uRw3nnnpX+Xlh25wdpJ+KJKaNasWahdu3b44osvSmyP6y1btiz1NRtttFGqIhQnt3722Wfhgw8+COutt17YbLPNCm1atWoVtt122xKv69ChQ5g0aVIFXQlV/Z656KKLCr1fsTLmSSedFC644AL/x7GGivdSafdYo0aN0pDVNbkPqbn3S3Hxf/48++yz4aWXXgqbbLJJxmdKVbln4rDmWLwn/o/kOnXqpCUWbbnlllvS97HnnbWL8EWVEHshdt555zTXpnivVVzv3LnzSl8b/0/QxhtvHL7//vvw5JNPhsMOO6ywLw7lWLaEb5zL07Zt2wq4CqrDPTN//vwSPWFR/OM6HpuaJ95Lxe+xKA5Xzd9jP+Q+pObdL1GswxCD15AhQ8I///nP9FgLaq5V3TMHHnhg+N///pcqIeaXOJc9DoWP38d/n1jLlEPRDsjEo48+mqtfv35u0KBBuffeey93xhln5DbYYIPc9OnT0/6TTjopd+mllxbav/rqq7knn3wy9/HHH+dGjRqVO+CAA3Lt27fPffvtt4U2Y8aMydWpUyd3/fXX5z766KPc4MGDcw0bNsw9/PDDlXKNrP33TK9evXIbb7xx7tlnn81NnDgx99RTT+WaNWuWKlJR9cWKYW+++WZa4j+RN910U/r+s88+S/vj/RLvm7xPPvkk/c646KKLcu+//37u9ttvz9WuXTs3bNiwMt+HVF0Vcb+cddZZucaNG+defvnl3LRp0wrL/PnzK+UaWfvvmWWpdrh2E76oUm699dbcpptumqtXr14q3xz/WC7+yyb+YZwX/+Hq0KFD+qOnadOm6ZfZlClTljvmM888k+vYsWNqt8022+TuueeezK6HqnfPzJ49O/2jFo/ZoEGD3GabbZa7/PLLc4sWLcr0uqgYL730UvqDaNklf5/Er/G+WfY1O+64Y7rH4v3wwAMPrNZ9SNVVEfdLaceLS2n3FVVPRf2OKU74WrsVxf9Udu8bAABAdWfOFwAAQAaELwAAgAwIXwAAABkQvgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAVIKioqIwdOjQyj4NADIkfAFQ4/Tu3TuFn2WXgw8+uLJPDYBqrE5lnwAAVIYYtB544IES2+rXr19p5wNA9afnC4AaKQatli1bllg23HDDtC/2gt15552hW7duYZ111gmbbbZZeOKJJ0q8/n//+1844IAD0v6mTZuGM844I8ydO7dEm/vvvz9st9126b1atWoVzjnnnBL7v/rqq3D44YeHhg0bhi233DI8/fTTGVw5AJVF+AKAUlxxxRXhiCOOCG+99VY44YQTwrHHHhvef//9tG/evHmha9euKay99tpr4fHHHw8vvvhiiXAVw1vfvn1TKItBLQarLbbYosR7XH311eHoo48Ob7/9djjkkEPS+3zzzTeZXysA2SjK5XK5jN4LANaaOV8PP/xwaNCgQYntv/rVr9ISe77OPPPMFKDy9thjj/CjH/0o3HHHHeHee+8Nl1xySZg8eXJYd9110/7nnnsudO/ePUydOjW0aNEibLzxxqFPnz7huuuuK/Uc4nv0798/XHvttYVAt95664Xnn3/e3DOAasqcLwBqpP33379EuIqaNGlS+L5z584l9sX1cePGpe9jD1inTp0KwSvaa6+9wtKlS8P48eNTsIoh7MADD1zpOeywww6F7+OxGjVqFGbMmPGDrw2AtZPwBUCNFMPOssMAy0ucB1YWdevWLbEeQ1sMcABUT+Z8AUApXn311eXWO3TokL6PX+NcsDhUMO/f//53qFWrVth6663D+uuvH9q1axdGjBiR+XkDsPbS8wVAjbRo0aIwffr0Etvq1KkTmjVrlr6PRTR22WWXsPfee4fBgweHMWPGhPvuuy/ti4UxrrzyytCrV69w1VVXhS+//DKce+654aSTTkrzvaK4Pc4ba968eaqaOGfOnBTQYjsAaibhC4AaadiwYan8e3Gx1+qDDz4oVCJ89NFHw9lnn53a/eUvfwnbbrtt2hdLw7/wwgvhvPPOC7vuumtaj5URb7rppsKxYjBbuHBh+MMf/hAuvPDCFOqOPPLIjK8SgLWJaocAsIw492rIkCGhR48elX0qAFQj5nwBAABkQPgCAADIgDlfALAMI/IBqAh6vgAAADIgfAEAAGRA+AIAAMiA8AUAAJAB4QsAACADwhcAAEAGhC8AAIAMCF8AAACh4v0f3uErqiu15QgAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_losses = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    epoch_loss = 0.0\n",
        "    count = 0\n",
        "\n",
        "    # for batch_idx, (images, path_lengths, nodes_astar, nodes_bfs) in enumerate(tqdm(dataloader, desc=f\"Training epoch [{epoch+1}/{EPOCHS}]\")):\n",
        "    for batch_idx, (images, prompt) in enumerate(tqdm(dataloader, desc=f\"Training epoch [{epoch+1}/{EPOCHS}]\")):\n",
        "        unet.train()\n",
        "        images = images.to(device)\n",
        "        # path_lengths = path_lengths.float().to(device)\n",
        "        # nodes_astar = nodes_astar.float().to(device)\n",
        "\n",
        "        # Step 1: Encode images to latents using VAE\n",
        "        with torch.no_grad():\n",
        "            z = vae.encode(images).latent_dist.sample()  # shape: (B, 4, 64, 64)\n",
        "\n",
        "        # Step 2: Sample timesteps & add noise\n",
        "        timesteps = torch.randint(0, NUM_TIMESTEPS, (z.size(0),), device=device).long()\n",
        "        noise = torch.randn_like(z)\n",
        "        noisy_z = scheduler.add_noise(z, noise, timesteps)\n",
        "\n",
        "        # # Step 3: Prepare conditional and unconditional embeddings\n",
        "        # cond_input = torch.stack([path_lengths, nodes_astar], dim=-1)\n",
        "        # cond_embed = custom_diffusion_model.condition_multidimensional_embedding(cond_input)\n",
        "   \n",
        "        # zero_input = torch.zeros_like(cond_input)\n",
        "        # uncond_embed = custom_diffusion_model.condition_multidimensional_embedding(zero_input)\n",
        "\n",
        "        # context = torch.cat([uncond_embed, cond_embed], dim=0)       \n",
        "\n",
        "        inputs = tokenizer(prompt, padding=\"max_length\", max_length=77, return_tensors=\"pt\").to(device)\n",
        "        with torch.no_grad():\n",
        "            cond_embed = text_encoder(**inputs).last_hidden_state\n",
        "\n",
        "        # For unconditional context\n",
        "        uncond_prompt = [\"\"] * images.size(0)\n",
        "        uncond_inputs = tokenizer(uncond_prompt, padding=\"max_length\", max_length=77, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            uncond_embed = text_encoder(**uncond_inputs).last_hidden_state\n",
        "\n",
        "        # Combine for classifier-free guidance\n",
        "        context = torch.cat([uncond_embed, cond_embed], dim=0)\n",
        "\n",
        "        # Step 4: Forward pass with classifier-free guidance\n",
        "        noisy_z = noisy_z.repeat(2, 1, 1, 1)                          \n",
        "        timesteps = timesteps.repeat_interleave(2)                   \n",
        "\n",
        "        noise_pred = unet(noisy_z, timesteps, encoder_hidden_states=context).sample\n",
        "        noise_uncond, noise_cond = noise_pred.chunk(2)\n",
        "\n",
        "        guided_noise = noise_uncond + GUIDANCE_SCALE * (noise_cond - noise_uncond)\n",
        "\n",
        "        # Step 5: Loss and optimization\n",
        "        # loss = F.smooth_l1_loss(guided_noise, noise)\n",
        "        loss = F.mse_loss(guided_noise, noise)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * images.size(0)\n",
        "        count += images.size(0)\n",
        "\n",
        "    avg_loss = epoch_loss / count\n",
        "    train_losses.append(avg_loss)\n",
        "    print(f\"[Epoch {epoch+1}] Loss: {avg_loss:.6f}\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, EPOCHS + 1), train_losses, marker='o', label='Train Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss Graph')\n",
        "plt.legend()\n",
        "file_name = f\"loss_curve_diffusion_multi_feat_{formatted_time}\"\n",
        "plt.savefig(os.path.join(loss_curves_folder, file_name))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96439c5e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from diffusers import StableDiffusionPipeline, DiffusionPipeline\n",
        "from diffusers.utils import convert_state_dict_to_diffusers\n",
        "from peft import get_peft_model_state_dict\n",
        "\n",
        "if not os.path.exists(f\"../data/loss_curves_{formatted_time}/lora/\"):\n",
        "    os.makedirs(f\"../data/loss_curves_{formatted_time}/lora/\")\n",
        "# if not os.path.exists(f\"../data/lora_test/lora/\"):\n",
        "#     os.makedirs(f\"../data/lora_test/lora/\")\n",
        "unet_lora_state_dict = convert_state_dict_to_diffusers(\n",
        "    get_peft_model_state_dict(unet)\n",
        ")\n",
        "StableDiffusionPipeline.save_lora_weights(\n",
        "    save_directory=f\"../data/loss_curves_{formatted_time}/lora/lora_weights\",\n",
        "    # save_directory=f\"../data/lora_test/lora/lora_weights\",\n",
        "    unet_lora_layers=unet_lora_state_dict,\n",
        "    safe_serialization=True,\n",
        ")\n",
        "torch.save(unet.state_dict(), f\"../data/loss_curves_{formatted_time}/lora/diffusion_weights_multi_feat_lora.pth\")\n",
        "# torch.save(unet.state_dict(), f\"../data/lora_test/lora/diffusion_weights_multi_feat_lora.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "97eb8ffb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e6475a222d5451fb5f43c66ccea1c9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/I749793/.pyenv/versions/3.11.0/envs/classifierGuidance_3.11.0_venv/lib/python3.11/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "pipe = DiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    unet=unet,\n",
        "    torch_dtype=torch.float16,  # or torch.float32\n",
        ")\n",
        "pipe.load_lora_weights(\n",
        "    pretrained_model_name_or_path_or_dict=f\"../data/loss_curves_{formatted_time}/lora/lora_weights\",\n",
        "    # pretrained_model_name_or_path_or_dict=f\"../data/lora_test/lora/lora_weights\",\n",
        "    adapter_name=\"custom_lora\",  # optional name\n",
        "    from_local=True\n",
        ")\n",
        "unet = pipe.unet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "172368e1",
      "metadata": {},
      "source": [
        "### Stable Diffusion Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "702fdd80",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def generate_maze_from_test(sample_idx=None, num_steps=50):\n",
        "    unet.eval()\n",
        "    scheduler.set_timesteps(num_steps)\n",
        "    \n",
        "    # if sample_idx is None:\n",
        "    #     sample_idx = random.randint(0, len(dataset) - 1)\n",
        "\n",
        "    idx = np.random.randint(len(dataset))\n",
        "    test_img = dataset[idx][0].unsqueeze(0).to(torch.float32).to(device)\n",
        "    prompt = f\"a maze with difficulty 3\"\n",
        "\n",
        "    \n",
        "    # test_img, test_path_length, nodes_astar, nodes_bfs = test_dataset[sample_idx]\n",
        "    # test_img, prompt = test_dataset[sample_idx]\n",
        "    # path_tensor = torch.tensor([test_path_length]).float().to(device)\n",
        "    # nodes_astar_tensor = torch.tensor([nodes_astar]).float().to(device)\n",
        "    # combined_features = torch.stack((path_tensor, nodes_astar_tensor), dim=-1)\n",
        "    # context = diffusion_model.condition_multidimensional_embedding(\n",
        "    #     torch.tensor([test_path_length], device=device).float()\n",
        "    # )\n",
        "\n",
        "    # context = custom_diffusion_model.condition_multidimensional_embedding(combined_features)\n",
        "\n",
        "    inputs = tokenizer(prompt, padding=\"max_length\", max_length=77, return_tensors=\"pt\").to(device)\n",
        "    with torch.no_grad():\n",
        "        context = text_encoder(**inputs).last_hidden_state\n",
        "    \n",
        "    latent = torch.randn((1, 4, 8, 8), device=device)\n",
        "    \n",
        "    for t in scheduler.timesteps:\n",
        "        timestep = torch.tensor([t], device=device)\n",
        "        with torch.no_grad():\n",
        "            pred = unet(latent, timestep, encoder_hidden_states=context).sample\n",
        "        latent = scheduler.step(pred, t, latent).prev_sample\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        generated_image = vae.decode(latent/0.18215).sample\n",
        "        # generated_image = decoder(latent / 0.18215)\n",
        "    \n",
        "    # return generated_image, test_img, test_path_length\n",
        "    return generated_image, test_img, prompt\n",
        "\n",
        "# def visualize_sample(sample, original, difficulty):\n",
        "#     sample = sample.permute(0, 2, 3, 1).cpu().numpy()\n",
        "#     original = original.permute(0, 2, 3, 1).cpu().numpy()\n",
        "\n",
        "#     generated = visualize_grid_world(sample)\n",
        "#     original = visualize_grid_world(sample)\n",
        "    \n",
        "#     plt.figure(figsize=(10, 5))\n",
        "#     plt.subplot(1, 2, 1)\n",
        "#     # plt.imshow(generated.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "#     # plt.imshow(generated.squeeze(0).cpu().numpy(), cmap='gray')\n",
        "#     plt.imshow(generated.squeeze(0), cmap='gray')\n",
        "#     plt.title(f\"Generated Maze, {difficulty}\")\n",
        "#     plt.axis(\"off\")\n",
        "\n",
        "#     plt.subplot(1, 2, 2)\n",
        "#     # plt.imshow(original.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "#     # plt.imshow(original.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "#     # plt.imshow(original.squeeze(0).cpu().numpy(), cmap='gray')\n",
        "#     plt.imshow(original.squeeze(0), cmap='gray')\n",
        "#     plt.title(\"Original Test Maze\")\n",
        "#     plt.axis(\"off\")\n",
        "#     file_name = f\"diffusion_image_generation_multi_feat_{formatted_time}\"\n",
        "#     plt.savefig(os.path.join(loss_curves_folder, file_name))\n",
        "#     plt.show()\n",
        "\n",
        "def visualize_sample(sample, original, difficulty):\n",
        "    # sample/original: (1, 3, 10, 10) — from diffusion\n",
        "    sample = sample.squeeze(0).permute(1, 2, 0).cpu().numpy()  # (10, 10, 3)\n",
        "    original = original.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "    generated_rgb = visualize_grid_world(sample)\n",
        "    original_rgb = visualize_grid_world(original)\n",
        "\n",
        "    plt.figure(figsize=(6, 3))  # Adjust this for proper aspect ratio\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(generated_rgb)\n",
        "    plt.title(f\"Generated Maze, {difficulty}\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(original_rgb)\n",
        "    plt.title(\"Original Test Maze\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    file_name = f\"diffusion_image_generation_multi_feat_{formatted_time}\"\n",
        "    plt.savefig(os.path.join(loss_curves_folder, file_name))\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "ff2084bb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generated, original, test_path_length = generate_maze_from_test(num_steps=100)\n",
        "# image = generated[0].detach().cpu()\n",
        "visualize_sample(generated, original, test_path_length)\n",
        "# # Convert from [-1, 1] to [0, 1]\n",
        "# image = (image + 1.0) / 2.0\n",
        "# generated = torch.clamp(image, 0.0, 1.0)\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.imshow(generated.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# # plt.imshow(generated.squeeze(0).cpu().numpy(), cmap='gray')\n",
        "# plt.title(f\"Generated Maze, {test_path_length}\")\n",
        "# plt.axis(\"off\")\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# # plt.imshow(original.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# plt.imshow(original.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# plt.title(\"Original Test Maze\")\n",
        "# plt.axis(\"off\")\n",
        "# file_name = f\"diffusion_image_generation_multi_feat_{formatted_time}\"\n",
        "# plt.savefig(os.path.join(loss_curves_folder, file_name))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "0c103085",
      "metadata": {},
      "outputs": [],
      "source": [
        "# generated, original, test_path_length = generate_maze_from_test(num_steps=100)\n",
        "# image = generated[0].detach().cpu()\n",
        "\n",
        "# # Convert from [-1, 1] to [0, 1]\n",
        "# image = (image + 1.0) / 2.0\n",
        "# generated = torch.clamp(image, 0.0, 1.0)\n",
        "\n",
        "# visualize_sample(generated, test_path_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "a01ba929",
      "metadata": {},
      "outputs": [],
      "source": [
        "# generated, original, test_path_length = generate_maze_from_test(num_steps=100)\n",
        "# image = generated[0].detach().cpu()\n",
        "\n",
        "# # Convert from [-1, 1] to [0, 1]\n",
        "# image = (image + 1.0) / 2.0\n",
        "# generated = torch.clamp(image, 0.0, 1.0)\n",
        "\n",
        "# generated = (generated > 0.5).float()\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# plt.figure(figsize=(10, 5))\n",
        "# plt.subplot(1, 2, 1)\n",
        "# plt.imshow(generated.squeeze(0).permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# # plt.imshow(generated.squeeze(0).cpu().numpy(), cmap='gray')\n",
        "# plt.title(f\"Generated Maze, {test_path_length}\")\n",
        "# plt.axis(\"off\")\n",
        "\n",
        "# plt.subplot(1, 2, 2)\n",
        "# # plt.imshow(original.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# plt.imshow(original.permute(1, 2, 0).cpu().numpy(), cmap='gray')\n",
        "# plt.title(\"Original Test Maze\")\n",
        "# plt.axis(\"off\")\n",
        "# file_name = f\"diffusion_image_generation_multi_feat_{formatted_time}_greater_05\"\n",
        "# plt.savefig(os.path.join(loss_curves_folder, file_name))\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2853145",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cdc7703",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "classifierGuidance_3.11.0_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
